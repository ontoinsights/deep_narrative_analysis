{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67805eb7",
   "metadata": {},
   "source": [
    "# Querying news articles via Stardog\n",
    "\n",
    "News articles ingested in the notebook, Demo_Article_Ingest, with execution/visualization of these in the cells below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24554d45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T17:51:44.188449Z",
     "start_time": "2024-06-05T17:51:44.110939Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import stardog\n",
    "\n",
    "sd_dna = 'dna'\n",
    "sd_conn_details = {'endpoint': os.environ.get('STARDOG_ENDPOINT'),\n",
    "                   'username': os.getenv('STARDOG_USER'),\n",
    "                   'password': os.environ.get('STARDOG_PASSWORD')}\n",
    "dna = 'urn:ontoinsights:dna'\n",
    "\n",
    "conn = stardog.Connection(sd_dna, **sd_conn_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ee606f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T17:51:45.232848Z",
     "start_time": "2024-06-05T17:51:45.229975Z"
    }
   },
   "outputs": [],
   "source": [
    "article_collection = ['fl_abortion', 'landslide', 'trump_trial']\n",
    "\n",
    "sources = ['Al Jazeera', 'Breitbart', 'CNN', 'Fox News', 'Huffington Post',\n",
    "           'New York Times', 'Wall Street Journal', 'Washington Times' ]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d4a1f06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T17:51:46.683550Z",
     "start_time": "2024-06-05T17:51:46.678367Z"
    }
   },
   "outputs": [],
   "source": [
    "# Queries\n",
    "\n",
    "# Article length (number of sentences)\n",
    "length_query = \\\n",
    "    'prefix : <urn:ontoinsights:dna:> prefix dna: <urn:ontoinsights:dna:> prefix dc: <http://purl.org/dc/terms/> ' \\\n",
    "    'select * where { ' \\\n",
    "    '    graph ?defGraph { ?narrative a :Narrative ; :source ?source ; :number_sentences ?numbSents} ' \\\n",
    "    '} ORDER BY DESC(?numbSents)'\n",
    "\n",
    "# Person or org mentions\n",
    "names_query = \\\n",
    "    'prefix : <urn:ontoinsights:dna:> prefix dna: <urn:ontoinsights:dna:> prefix dc: <http://purl.org/dc/terms/> ' \\\n",
    "    'select ?agent (COUNT(?sent) as ?cnt) where { ' \\\n",
    "    '    ?type rdfs:subClassOf* ?baseType ' \\\n",
    "    '    {graph ?defGraph {?agent a ?type . FILTER NOT EXISTS{?agent a :GeopoliticalEntity}}} ' \\\n",
    "    '    {graph ?narrGraph {?sent a :Sentence ; :mentions ?agent}} ' \\\n",
    "    '} GROUP BY ?agent'\n",
    "\n",
    "# Sentiment\n",
    "sentiment_query = \\\n",
    "    'prefix : <urn:ontoinsights:dna:> prefix dna: <urn:ontoinsights:dna:> prefix dc: <http://purl.org/dc/terms/> ' \\\n",
    "    'select ?sentiment (COUNT(?sent) as ?cnt) where { ' \\\n",
    "    '    graph ?narrGraph {?sent a :Sentence ; :sentiment ?sentiment} ' \\\n",
    "    '} GROUP BY ?sentiment'\n",
    "\n",
    "# Average grade level\n",
    "grade_query = \\\n",
    "    'prefix : <urn:ontoinsights:dna:> prefix dna: <urn:ontoinsights:dna:> prefix dc: <http://purl.org/dc/terms/> ' \\\n",
    "    'select (COUNT(?sent) as ?cnt) (MIN(?grade) as ?min) (MAX(?grade) as ?max) (AVG(?grade) as ?avg) where { ' \\\n",
    "    '    graph ?narrGraph {?sent a :Sentence ; :grade_level ?grade} ' \\\n",
    "    '}'\n",
    "\n",
    "# Rhetorical devices (note that only a subset of the devices are reported by this query)\n",
    "rhetorical_query = \\\n",
    "    'prefix : <urn:ontoinsights:dna:> prefix dna: <urn:ontoinsights:dna:> prefix dc: <http://purl.org/dc/terms/> ' \\\n",
    "    'select ?device (COUNT(?sent) as ?cnt) where { ' \\\n",
    "    '    VALUES ?device {\"ad baculum\" \"ad hominem\" \"ad populum\" \"exceptionalism\" \"expletive\" \"hyperbole\" ' \\\n",
    "    '                    \"invective\" \"loaded language\" \"paralipsis\" \"pathos\"} ' \\\n",
    "    '    {graph ?narrGraph {?sent a :Sentence ; :rhetorical_device ?device}} ' \\\n",
    "    '} GROUP BY ?device'\n",
    "\n",
    "# Number of overall quotations and their attribution\n",
    "quote_query = \\\n",
    "    'prefix : <urn:ontoinsights:dna:> prefix dna: <urn:ontoinsights:dna:> prefix dc: <http://purl.org/dc/terms/> ' \\\n",
    "    'select (COUNT(?quote) as ?numbQuotes) where { ' \\\n",
    "    '    graph ?narrGraph { ?quote a :Quote} ' \\\n",
    "    '}'\n",
    "attribution_query = \\\n",
    "    'prefix : <urn:ontoinsights:dna:> prefix dna: <urn:ontoinsights:dna:> prefix dc: <http://purl.org/dc/terms/> ' \\\n",
    "    'select ?agent ?label (COUNT(?quote) as ?cnt) where { ' \\\n",
    "    '    graph ?narrGraph {?quote a :Quote ; :attributed_to ?agent . ' \\\n",
    "    '        OPTIONAL {?agent rdfs:label ?label}} ' \\\n",
    "    '} GROUP BY ?agent ?label'\n",
    "# Get label in case the quote is attributed to non-specific entities such as a \"court's justices\"\n",
    "\n",
    "# Quotation sentiment, avg grade level and rhetorical devices\n",
    "# Queries from above with ?sent and :Sentence replaced by ?quote and :Quote\n",
    "quote_sentiment_query = \\\n",
    "    'prefix : <urn:ontoinsights:dna:> prefix dna: <urn:ontoinsights:dna:> prefix dc: <http://purl.org/dc/terms/> ' \\\n",
    "    'select ?sentiment (COUNT(?quote) as ?cnt) where { ' \\\n",
    "    '    graph ?narrGraph {?quote a :Quote ; :sentiment ?sentiment} ' \\\n",
    "    '} GROUP BY ?sentiment'\n",
    "quote_rhetorical_query = \\\n",
    "    'prefix : <urn:ontoinsights:dna:> prefix dna: <urn:ontoinsights:dna:> prefix dc: <http://purl.org/dc/terms/> ' \\\n",
    "    'select ?device (COUNT(?quote) as ?cnt) where { ' \\\n",
    "    'VALUES ?device {\"ad baculum\" \"ad hominem\" \"ad populum\" \"exceptionalism\" \"expletive\" \"hyperbole\" ' \\\n",
    "    '                \"invective\" \"loaded language\" \"paralipsis\" \"pathos\"} ' \\\n",
    "    '    {graph ?narrGraph {?quote a :Quote ; :rhetorical_device ?device}} ' \\\n",
    "    '} GROUP BY ?device'\n",
    "\n",
    "# Appeal\n",
    "appeal_query = \\\n",
    "    'prefix : <urn:ontoinsights:dna:> prefix dna: <urn:ontoinsights:dna:> prefix dc: <http://purl.org/dc/terms/> ' \\\n",
    "    'select * where { ' \\\n",
    "    '    graph ?defGraph {?narrative a :Narrative ; ' \\\n",
    "    '        :ranking_conservative ?conserv ; :ranking_liberal ?lib ; :ranking_neutral ?neutral ; ' \\\n",
    "    '        :interpretation_conservative ?conserv_int ; :interpretation_liberal ?lib_int ; ' \\\n",
    "    '        :interpretation_neutral ?conserv_neutral} ' \\\n",
    "    '}'\n",
    "\n",
    "# Events\n",
    "event_query = \\\n",
    "    'prefix : <urn:ontoinsights:dna:> prefix dna: <urn:ontoinsights:dna:> prefix dc: <http://purl.org/dc/terms/> ' \\\n",
    "    'select distinct ?offset ?text ?eventType ?eventText where { ' \\\n",
    "    '    ?eventType rdfs:subClassOf* :EventAndState . ' \\\n",
    "    '    {graph ?narrGraph {?sent a :Sentence ; :offset ?offset ; :text ?text ; :has_semantic ?event . ' \\\n",
    "    '                {{?event a ?eventType ; :text ?eventText . FILTER NOT EXISTS{?event :negated true}} ' \\\n",
    "    '                     UNION {?event :has_topic ?topic . ?topic rdf:type ?eventType ; :text ?eventText} ' \\\n",
    "    '                     UNION {?event :has_quantification ?quant . ?quant rdf:type ?eventType; ' \\\n",
    "    '                            :text ?eventType}}}} ' \\\n",
    "    '} ORDER BY ?offset ?eventType '"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca6fbd3",
   "metadata": {},
   "source": [
    "## Query processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6fd3580",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T17:51:51.409491Z",
     "start_time": "2024-06-05T17:51:49.080313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fl_abortion\n",
      "source -> # sentences, % quotes\n",
      "{'CNN': [47, 26], 'Huffington Post': [37, 35], 'New York Times': [36, 25], 'Wall Street Journal': [36, 14], 'Al Jazeera': [35, 20], 'Breitbart': [32, 28], 'Washington Times': [17, 0], 'Fox News': [13, 54]}\n",
      "\n",
      "landslide\n",
      "source -> # sentences, % quotes\n",
      "{'Huffington Post': [32, 19], 'Washington Times': [28, 21], 'Al Jazeera': [19, 21], 'Breitbart': [16, 19], 'Fox News': [15, 33], 'New York Times': [15, 0], 'CNN': [13, 0]}\n",
      "\n",
      "trump_trial\n",
      "source -> # sentences, % quotes\n",
      "{'New York Times': [122, 16], 'Fox News': [64, 56], 'Wall Street Journal': [60, 18], 'Al Jazeera': [51, 47], 'Washington Times': [50, 16], 'Huffington Post': [44, 14], 'Breitbart': [28, 18], 'CNN': [23, 39]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Overall counts of sentences/quotes per article\n",
    "for topic in article_collection:\n",
    "    counts_dict = dict()  # Key = Narrative source; Value = array of number sentences, number quotes \n",
    "    defGraph = f'dna:{topic}_default'\n",
    "    query_results = conn.select(length_query.replace('?defGraph', defGraph), \n",
    "                                content_type='application/sparql-results+json')\n",
    "    if 'results' in query_results and 'bindings' in query_results['results']:\n",
    "        bindings = query_results['results']['bindings']\n",
    "    else:\n",
    "        bindings = []\n",
    "    for binding in bindings:\n",
    "        narr = binding['narrative']['value'].split(':dna:Narrative_')[1]\n",
    "        source = binding['source']['value']\n",
    "        numbSents = int(binding['numbSents']['value'])\n",
    "        narrGraph = f'dna:{topic}_{narr}'\n",
    "        query_results = conn.select(quote_query.replace('?narrGraph', narrGraph), \n",
    "                                    content_type='application/sparql-results+json')\n",
    "        if 'results' in query_results and 'bindings' in query_results['results']:\n",
    "            quote_binding = query_results['results']['bindings'][0]\n",
    "            numbQuotes = int(quote_binding['numbQuotes']['value'])\n",
    "            counts_dict[source] = [numbSents, round(numbQuotes * 100/numbSents)]\n",
    "    print(topic)\n",
    "    print('source -> # sentences, % quotes')\n",
    "    print(counts_dict)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bf5adde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T17:51:55.648044Z",
     "start_time": "2024-06-05T17:51:53.616940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fl_abortion\n",
      "source -> %pos, %neg, %neutral of all sentences\n",
      "{'CNN': [89, 4, 6], 'Huffington Post': [0, 92, 8], 'New York Times': [3, 6, 92], 'Wall Street Journal': [92, 3, 6], 'Al Jazeera': [0, 94, 6], 'Breitbart': [81, 0, 19], 'Washington Times': [0, 12, 88], 'Fox News': [62, 15, 23]}\n",
      "\n",
      "landslide\n",
      "source -> %pos, %neg, %neutral of all sentences\n",
      "{'Huffington Post': [0, 94, 6], 'Washington Times': [0, 93, 7], 'Al Jazeera': [0, 84, 16], 'Breitbart': [0, 94, 6], 'Fox News': [0, 100, 0], 'New York Times': [7, 27, 67], 'CNN': [0, 92, 8]}\n",
      "\n",
      "trump_trial\n",
      "source -> %pos, %neg, %neutral of all sentences\n",
      "{'New York Times': [0, 5, 95], 'Fox News': [0, 97, 3], 'Wall Street Journal': [0, 75, 25], 'Al Jazeera': [0, 10, 90], 'Washington Times': [0, 6, 94], 'Huffington Post': [2, 2, 95], 'Breitbart': [79, 18, 4], 'CNN': [0, 35, 65]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Overall % of sentences with pos, neg, neutral sentiments per article\n",
    "for topic in article_collection:\n",
    "    counts_dict = dict()  # Key = Narrative source; Value = array of percentage pos, neg, neutral\n",
    "    defGraph = f'dna:{topic}_default'\n",
    "    query_results = conn.select(length_query.replace('?defGraph', defGraph), \n",
    "                                content_type='application/sparql-results+json')\n",
    "    if 'results' in query_results and 'bindings' in query_results['results']:\n",
    "        bindings = query_results['results']['bindings']\n",
    "    else:\n",
    "        bindings = []\n",
    "    for binding in bindings:\n",
    "        narr = binding['narrative']['value'].split(':dna:Narrative_')[1]\n",
    "        source = binding['source']['value']\n",
    "        numbSents = int(binding['numbSents']['value'])\n",
    "        narrGraph = f'dna:{topic}_{narr}'\n",
    "        query_results = conn.select(sentiment_query.replace('?narrGraph', narrGraph), \n",
    "                                    content_type='application/sparql-results+json')\n",
    "        if 'results' in query_results and 'bindings' in query_results['results']:\n",
    "            sent_bindings = query_results['results']['bindings']\n",
    "        else:\n",
    "            sent_bindings = []\n",
    "        numbPos = numbNeg = numbNeutral = 0\n",
    "        for sent_binding in sent_bindings:\n",
    "            sentiment = sent_binding['sentiment']['value']\n",
    "            cnt = int(sent_binding['cnt']['value'])\n",
    "            if sentiment == 'positive':\n",
    "                numbPos = cnt\n",
    "            elif sentiment == 'negative':\n",
    "                numbNeg = cnt\n",
    "            else:\n",
    "                numbNeutral = cnt\n",
    "        counts_dict[source] = [round(numbPos * 100/numbSents), round(numbNeg * 100/numbSents), round(numbNeutral * 100/numbSents)]\n",
    "    print(topic)\n",
    "    print('source -> %pos, %neg, %neutral of all sentences')\n",
    "    print(counts_dict)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8476056",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T17:52:05.047005Z",
     "start_time": "2024-06-05T17:51:58.237503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fl_abortion\n",
      "source -> %pos, %neg, %neutral of all full sentence quotes\n",
      "{'Al Jazeera': [43, 43, 14], 'Wall Street Journal': [60, 0, 40], 'Breitbart': [22, 33, 44], 'Fox News': [14, 86, 0], 'CNN': [58, 17, 25], 'Huffington Post': [23, 38, 38], 'New York Times': [33, 67, 0]}\n",
      "\n",
      "landslide\n",
      "source -> %pos, %neg, %neutral of all full sentence quotes\n",
      "{'Al Jazeera': [0, 100, 0], 'Breitbart': [0, 100, 0], 'Fox News': [0, 40, 60], 'Washington Times': [0, 67, 33], 'Huffington Post': [0, 67, 33]}\n",
      "\n",
      "trump_trial\n",
      "source -> %pos, %neg, %neutral of all full sentence quotes\n",
      "{'Al Jazeera': [21, 54, 25], 'Wall Street Journal': [36, 45, 18], 'Breitbart': [0, 40, 60], 'Fox News': [22, 47, 31], 'Washington Times': [12, 62, 25], 'CNN': [0, 56, 44], 'Huffington Post': [17, 33, 50], 'New York Times': [21, 42, 37]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Overall % of quotes with pos, neg, neutral sentiments per article\n",
    "for topic in article_collection:\n",
    "    quote_counts_dict = dict()  # Key = Narrative source; Value = array of percentage pos, neg, neutral \n",
    "    response = requests.get(f'http://127.0.0.1:5000/dna/v1/repositories/narratives?repository={topic}')\n",
    "    result = response.json()\n",
    "    narr_dict = dict()\n",
    "    for narrative in result['narratives']:\n",
    "        narr_dict[narrative['narrativeId']] = narrative['narrativeMetadata']['source']\n",
    "    for narr_id in narr_dict.keys():\n",
    "        narrGraph = f'dna:{topic}_{narr_id}'\n",
    "        query_results = conn.select(quote_query.replace('?narrGraph', narrGraph), \n",
    "                                    content_type='application/sparql-results+json')\n",
    "        numbQuotes = 0\n",
    "        if 'results' in query_results and 'bindings' in query_results['results']:\n",
    "            quote_binding = query_results['results']['bindings'][0]\n",
    "            numbQuotes = int(quote_binding['numbQuotes']['value'])\n",
    "        if numbQuotes == 0:\n",
    "            continue\n",
    "        query_results = conn.select(quote_sentiment_query.replace('?narrGraph', narrGraph), \n",
    "                                    content_type='application/sparql-results+json')\n",
    "        if 'results' in query_results and 'bindings' in query_results['results']:\n",
    "            sent_bindings = query_results['results']['bindings']\n",
    "        else:\n",
    "            sent_bindings = []\n",
    "        numbPos = numbNeg = numbNeutral = 0\n",
    "        for sent_binding in sent_bindings:\n",
    "            sentiment = sent_binding['sentiment']['value']\n",
    "            cnt = int(sent_binding['cnt']['value'])\n",
    "            if sentiment == 'positive':\n",
    "                numbPos = cnt\n",
    "            elif sentiment == 'negative':\n",
    "                numbNeg = cnt\n",
    "            else:\n",
    "                numbNeutral = cnt\n",
    "        quote_counts_dict[narr_dict[narr_id]] = [round(numbPos * 100/numbQuotes), round(numbNeg * 100/numbQuotes), round(numbNeutral * 100/numbQuotes)]\n",
    "    print(topic)\n",
    "    print('source -> %pos, %neg, %neutral of all full sentence quotes')\n",
    "    print(quote_counts_dict)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9647cc86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T17:52:19.380167Z",
     "start_time": "2024-06-05T17:52:07.495233Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fl_abortion dna:OrganizationalEntity\n",
      "entity -> array of counts for \n",
      "'Al Jazeera', 'Breitbart', 'CNN', 'Fox', 'Huffington Post', 'NYT', 'WSJ', 'Washington Times'\n",
      "{'Pew_Research_Center': [1, 0, 0, 0, 0, 0, 0, 0], 'Electoral_College': [2, 0, 0, 0, 0, 0, 0, 0], 'Center_for_Reproductive_Rights': [1, 0, 0, 0, 0, 0, 0, 0], 'University_of_North_Florida_Public_Opinion_Research_Lab': [1, 0, 0, 0, 0, 0, 0, 0], 'ACLU_of_Florida': [1, 0, 0, 0, 0, 0, 0, 0], 'Florida_Supreme_Court': [3, 5, 3, 1, 1, 2, 1, 1], 'US_Supreme_Court': [2, 1, 2, 1, 2, 3, 2, 1], 'American_Civil_Liberties_Union': [1, 1, 0, 0, 2, 1, 0, 1], 'GOP': [0, 0, 0, 0, 0, 0, 2, 0], 'Alabama_Supreme_Court': [0, 0, 0, 0, 0, 0, 1, 0], 'White_House': [0, 0, 1, 0, 0, 0, 1, 0], 'Senate': [0, 0, 0, 0, 0, 0, 5, 0], 'House': [0, 0, 0, 0, 0, 0, 2, 0], 'Congress': [0, 0, 0, 0, 0, 0, 1, 0], 'Wall_Street_Journal': [0, 0, 0, 0, 0, 0, 1, 0], 'EMILYs_List': [0, 1, 0, 0, 0, 0, 0, 0], 'NBC_News': [0, 1, 0, 0, 0, 0, 0, 0], 'Florida_Voice_for_the_Unborn': [0, 1, 0, 0, 0, 0, 0, 0], 'Planned_Parenthood_of_Southwest_and_Central_Florida': [0, 1, 0, 0, 0, 0, 0, 0], 'Planned_Parenthood': [0, 3, 1, 0, 1, 2, 0, 1], 'Floridians_Protecting_Freedom': [0, 1, 1, 0, 1, 0, 0, 0], 'Susan_B_Anthony_Pro_Life_America': [0, 0, 0, 1, 0, 0, 0, 0], 'Fox_News_Digital': [0, 0, 0, 1, 0, 0, 0, 0], 'Society_of_Family_Planning': [0, 0, 0, 0, 0, 0, 0, 1], 'state_Supreme_Court': [0, 0, 2, 0, 1, 0, 0, 0], 'CNN': [0, 0, 1, 0, 0, 0, 0, 0], 'Legislature': [0, 0, 1, 0, 0, 0, 0, 0], 'Planned_Parenthood_of_South': [0, 0, 1, 0, 0, 0, 0, 0], 'Yes_on_4': [0, 0, 1, 0, 0, 1, 0, 0], 'HuffPost': [0, 0, 0, 0, 1, 0, 0, 0], 'Planned_Parenthood_Southwest': [0, 0, 0, 0, 1, 0, 0, 0]}\n",
      "\n",
      "landslide dna:OrganizationalEntity\n",
      "entity -> array of counts for \n",
      "'Al Jazeera', 'Breitbart', 'CNN', 'Fox', 'Huffington Post', 'NYT', 'WSJ', 'Washington Times'\n",
      "{'International_Organization_for_Migration': [1, 0, 0, 0, 1, 2, 0, 1], 'United_Nations': [1, 2, 2, 0, 1, 1, 0, 1], 'CARE_Australia': [1, 0, 0, 0, 0, 0, 0, 0], 'Al_Jazeera': [2, 0, 0, 0, 0, 0, 0, 0], 'World_Bank': [0, 1, 0, 0, 0, 0, 0, 0], 'AFP': [0, 1, 1, 0, 0, 0, 0, 0], 'Reuters': [0, 0, 0, 1, 0, 0, 0, 0], 'Australian_Broadcasting_Corp': [0, 0, 0, 1, 0, 0, 0, 0], 'PNG_Defence_Force': [0, 0, 0, 1, 0, 0, 0, 0], 'Department_of_Works_and_Highways': [0, 0, 0, 1, 0, 0, 0, 0], 'Barrick_Gold': [0, 0, 0, 2, 0, 0, 0, 0], 'Barrick_Niugini_Ltd': [0, 0, 0, 1, 0, 0, 0, 0], 'Zijin_Mining': [0, 0, 0, 1, 0, 0, 0, 0], 'Associated_Press': [0, 0, 0, 0, 1, 0, 0, 1], 'CARE_International': [0, 0, 0, 0, 1, 0, 0, 1], 'Mission_for_the_International_Organization_for_Migration': [0, 0, 1, 0, 0, 0, 0, 0], 'National_Disaster_Center': [0, 0, 0, 0, 1, 0, 0, 0]}\n",
      "\n",
      "trump_trial dna:OrganizationalEntity\n",
      "entity -> array of counts for \n",
      "'Al Jazeera', 'Breitbart', 'CNN', 'Fox', 'Huffington Post', 'NYT', 'WSJ', 'Washington Times'\n",
      "{'Trump_Media__Technology_Group': [1, 0, 0, 0, 0, 0, 0, 0], 'Al_Jazeera': [2, 0, 0, 0, 0, 0, 0, 0], 'MSNBC': [1, 0, 0, 0, 0, 0, 0, 0], 'House': [1, 0, 1, 0, 0, 2, 0, 0], 'TikTok': [0, 0, 0, 0, 0, 0, 1, 0], 'White_House': [0, 2, 1, 0, 0, 4, 2, 0], 'Wall_Street_Journal': [0, 0, 0, 0, 0, 1, 1, 0], 'National_Enquirer': [0, 0, 0, 0, 0, 1, 1, 1], 'Texas_Christian_University': [0, 1, 0, 0, 0, 0, 0, 0], 'Trump_Organization': [0, 0, 0, 2, 0, 0, 0, 2], 'Houses_of_Congress': [0, 0, 0, 1, 0, 0, 0, 0], 'Fox_News': [0, 0, 0, 1, 0, 0, 0, 0], 'Playboy': [0, 0, 0, 0, 0, 1, 0, 1], 'GOP': [0, 0, 1, 0, 0, 0, 0, 0], 'Source': [0, 0, 1, 0, 0, 0, 0, 0], 'CNN': [0, 0, 1, 0, 0, 0, 0, 0], 'FBI': [0, 0, 0, 0, 0, 1, 0, 0], 'Enquirer': [0, 0, 0, 0, 0, 1, 0, 0], 'Hells_Angels': [0, 0, 0, 0, 0, 1, 0, 0], 'Congress': [0, 0, 0, 0, 0, 1, 0, 0], 'Team_Stormy': [0, 0, 0, 0, 0, 1, 0, 0]}\n",
      "\n",
      "fl_abortion dna:Person\n",
      "entity -> array of counts for \n",
      "'Al Jazeera', 'Breitbart', 'CNN', 'Fox', 'Huffington Post', 'NYT', 'WSJ', 'Washington Times'\n",
      "{'Joe_Biden': [5, 2, 8, 0, 0, 0, 4, 0], 'Kamala_Harris': [1, 0, 0, 0, 0, 0, 0, 0], 'Ron_DeSantis': [3, 4, 6, 2, 3, 1, 1, 2], 'Donald_Trump': [2, 0, 7, 0, 0, 0, 5, 0], 'Julie_Chavez_Rodriguez': [0, 1, 1, 0, 0, 0, 1, 0], 'Brian_Hughes': [0, 0, 0, 0, 0, 0, 1, 0], 'Rick_Scott': [0, 0, 1, 0, 0, 0, 1, 0], 'Alice_Stewart': [0, 0, 0, 0, 0, 0, 1, 0], 'Matt_Grodsky': [0, 0, 0, 0, 0, 0, 2, 0], 'Ashley_Moody': [0, 2, 2, 3, 0, 0, 0, 0], 'Katie_Daniel': [0, 1, 0, 1, 0, 0, 0, 0], 'Jessica_Mackler': [0, 1, 0, 0, 0, 0, 0, 0], 'Susan_B_Anthony': [0, 1, 0, 0, 0, 0, 0, 0], 'Andrew_Shirvell': [0, 1, 0, 0, 0, 0, 0, 0], 'Julia_Friedland': [0, 0, 0, 1, 0, 0, 0, 0], 'Chavez_Rodriguez': [0, 0, 1, 0, 0, 0, 0, 0], 'Lauren_Brenzel': [0, 0, 1, 0, 2, 2, 0, 0], 'Alexandra_Mandado': [0, 0, 2, 0, 0, 0, 0, 0], 'Hillary_Clinton': [0, 0, 1, 0, 0, 0, 0, 0], 'Whitney_White': [0, 0, 0, 0, 2, 0, 0, 0], 'Sara_Boboltz': [0, 0, 0, 0, 1, 0, 0, 0], 'Robyn_Schickler': [0, 0, 0, 0, 1, 0, 0, 0], 'Cecilia_Grande': [0, 0, 0, 0, 2, 0, 0, 0], 'Carlos_Muniz': [0, 0, 0, 0, 1, 0, 0, 0], 'Jorge_Labarga': [0, 0, 0, 0, 0, 1, 0, 0], 'Erin_Grall': [0, 0, 0, 0, 0, 1, 0, 0], 'Danielle_Tallafuss': [0, 0, 0, 0, 0, 1, 0, 0], 'Jamie_R_Grosshans': [0, 0, 0, 0, 0, 1, 0, 0]}\n",
      "\n",
      "landslide dna:Person\n",
      "entity -> array of counts for \n",
      "'Al Jazeera', 'Breitbart', 'CNN', 'Fox', 'Huffington Post', 'NYT', 'WSJ', 'Washington Times'\n",
      "{'Serhan_Aktoprak': [3, 4, 3, 0, 7, 4, 0, 6], 'Justine_McMahon': [2, 0, 0, 0, 1, 0, 0, 1], 'Ninga_Role': [0, 0, 0, 3, 0, 0, 0, 0], 'James_Marape': [0, 0, 0, 2, 0, 0, 0, 0], 'Billy_Joseph': [0, 0, 0, 0, 1, 0, 0, 0], 'Laso_Mana': [0, 0, 0, 0, 1, 0, 0, 0]}\n",
      "\n",
      "trump_trial dna:Person\n",
      "entity -> array of counts for \n",
      "'Al Jazeera', 'Breitbart', 'CNN', 'Fox', 'Huffington Post', 'NYT', 'WSJ', 'Washington Times'\n",
      "{'Mike_Johnson': [3, 0, 1, 0, 0, 1, 0, 0], 'Donald_Trump_Jr': [1, 0, 0, 0, 0, 0, 0, 0], 'Michael_Tyler': [1, 0, 1, 2, 0, 0, 0, 0], 'Eric': [1, 0, 0, 0, 1, 0, 0, 2], 'Melanie_Sloan': [2, 0, 0, 0, 0, 0, 0, 0], 'John_Hendren': [1, 0, 0, 0, 0, 0, 0, 0], 'Joe_Biden': [4, 4, 4, 2, 0, 2, 2, 2], 'Michael_Cohen': [5, 2, 2, 20, 0, 33, 10, 5], 'Juan_Merchan': [4, 2, 2, 1, 3, 1, 3, 6], 'Stormy_Daniels': [1, 4, 3, 5, 0, 12, 7, 6], 'Todd_Blanche': [3, 1, 2, 9, 2, 7, 2, 0], 'Donald_Trump': [21, 13, 14, 29, 13, 62, 35, 25], 'Alvin_Bragg': [3, 0, 2, 6, 2, 11, 8, 2], 'Eric_Trump': [0, 0, 0, 0, 1, 0, 1, 0], 'Guilty': [0, 0, 0, 0, 0, 0, 1, 0], 'David_Pecker': [0, 0, 0, 0, 0, 7, 1, 2], 'Hope_Hicks': [0, 0, 0, 0, 0, 4, 1, 0], 'Cyrus_Vance': [0, 0, 0, 0, 0, 0, 1, 0], 'Hillary_Clinton': [0, 1, 0, 0, 0, 0, 0, 0], 'Keith_Gaddie': [0, 1, 0, 0, 0, 0, 0, 0], 'Joshua_Steinglass': [0, 0, 0, 5, 0, 1, 0, 0], 'TeamCohen': [0, 0, 0, 1, 0, 0, 0, 0], 'Soros': [0, 0, 0, 1, 0, 0, 0, 0], 'Allen_Weisselberg': [0, 0, 0, 1, 0, 2, 0, 0], 'Robert_Costello': [0, 0, 0, 0, 0, 0, 0, 1], 'Alina_Habba': [0, 0, 0, 0, 0, 0, 0, 1], 'Boris_Epshteyn': [0, 0, 0, 0, 0, 0, 0, 1], 'Vivek_Ramaswamy': [0, 0, 0, 0, 0, 0, 0, 1], 'JD_Vance': [0, 0, 0, 0, 0, 0, 0, 1], 'Karen_McDougal': [0, 0, 0, 0, 0, 0, 0, 1], 'Kaitlan_Collins': [0, 0, 1, 0, 0, 0, 0, 0], 'Juan_M_Merchan': [0, 0, 0, 0, 1, 1, 0, 0], 'Van_Gogh': [0, 0, 0, 0, 1, 0, 0, 0], 'Michael_McKee': [0, 0, 0, 0, 1, 0, 0, 0], 'E_Jean_Carroll': [0, 0, 0, 0, 0, 1, 0, 0], 'Susan_Hoffinger': [0, 0, 0, 0, 0, 2, 0, 0], 'Alvin_L_Bragg': [0, 0, 0, 0, 0, 1, 0, 0], 'Michael_D_Cohen': [0, 0, 0, 0, 0, 1, 0, 0], 'Allen_H_Weisselberg': [0, 0, 0, 0, 0, 1, 0, 0], 'Joe_Piscopo': [0, 0, 0, 0, 0, 1, 0, 0]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mentions of persons or orgs across 7-8 articles\n",
    "for baseType in ('dna:OrganizationalEntity', 'dna:Person'):\n",
    "    for topic in article_collection:\n",
    "        agent_mentions_dict = dict()  # Key = person or org instance; Value = array of counts by source\n",
    "        defGraph = f'dna:{topic}_default'\n",
    "        response = requests.get(f'http://127.0.0.1:5000/dna/v1/repositories/narratives?repository={topic}')\n",
    "        result = response.json()\n",
    "        narr_dict = dict()\n",
    "        for narrative in result['narratives']:\n",
    "            narr_dict[narrative['narrativeId']] = narrative['narrativeMetadata']['source']\n",
    "        for narr_id in narr_dict.keys():\n",
    "            narrGraph = f'dna:{topic}_{narr_id}'\n",
    "            query_results = conn.select(\n",
    "                names_query.replace('?baseType', baseType).replace('?defGraph', defGraph).replace('?narrGraph', narrGraph), \n",
    "                content_type='application/sparql-results+json')\n",
    "            if 'results' in query_results and 'bindings' in query_results['results']:\n",
    "                bindings = query_results['results']['bindings']\n",
    "            else:\n",
    "                bindings = []\n",
    "            for binding in bindings:\n",
    "                if 'agent' not in binding:     # No OrgEntities or no Persons mentioned in that article\n",
    "                    continue     \n",
    "                agent = binding['agent']['value'].split(':dna:')[1]\n",
    "                count = int(binding['cnt']['value'])\n",
    "                if agent in agent_mentions_dict.keys():\n",
    "                    count_array = agent_mentions_dict[agent]\n",
    "                else:\n",
    "                    count_array = [0, 0, 0, 0, 0, 0, 0, 0]    # Init new count array\n",
    "                count_array[sources.index(narr_dict[narr_id])] = count    # Should only be 1 count per agent per source\n",
    "                agent_mentions_dict[agent] = count_array\n",
    "        print(topic, baseType)\n",
    "        print(\"entity -> array of counts for \")\n",
    "        print(\"'Al Jazeera', 'Breitbart', 'CNN', 'Fox', 'Huffington Post', 'NYT', 'WSJ', 'Washington Times'\")\n",
    "        print(agent_mentions_dict)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efec4ef1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T17:52:27.031890Z",
     "start_time": "2024-06-05T17:52:22.174764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fl_abortion\n",
      "entity -> array of attribution counts for \n",
      "'Al Jazeera', 'Breitbart', 'CNN', 'Fox', 'Huffington Post', 'NYT', 'WSJ', 'Washington Times'\n",
      "{'Joe_Biden': [2, 0, 0, 0, 0, 0, 1, 0], 'Amendment_4': [1, 0, 0, 0, 0, 0, 0, 0], 'ACLU_of_Florida': [2, 0, 0, 0, 0, 0, 0, 0], 'Matt_Grodsky': [0, 0, 0, 0, 0, 0, 1, 0], 'Julie_Chavez_Rodriguez': [0, 0, 3, 0, 0, 0, 1, 0], 'Brian_Hughes': [0, 0, 0, 0, 0, 0, 1, 0], 'Alice_Stewart': [0, 0, 0, 0, 0, 0, 1, 0], 'Florida_Supreme_Court': [0, 1, 0, 0, 3, 0, 0, 0], 'Katie_Daniel': [0, 1, 0, 2, 0, 0, 0, 0], 'Ashley_Moody': [0, 0, 0, 2, 0, 0, 0, 0], 'Julia_Friedland': [0, 0, 0, 2, 0, 0, 0, 0], 'Donald_Trump': [0, 0, 1, 0, 0, 0, 0, 0], 'Lauren_Brenzel': [0, 0, 3, 0, 3, 2, 0, 0], 'Alexandra_Mandado': [0, 0, 2, 0, 0, 0, 0, 0], 'Cecilia_Grande': [0, 0, 0, 0, 2, 0, 0, 0], 'Whitney_White': [0, 0, 0, 0, 1, 0, 0, 0], 'Robyn_Schickler': [0, 0, 0, 0, 3, 0, 0, 0], 'Carlos_Muniz': [0, 0, 0, 0, 1, 0, 0, 0], 'Jamie_R_Grosshans': [0, 0, 0, 0, 0, 1, 0, 0], 'Jorge_Labarga': [0, 0, 0, 0, 0, 2, 0, 0], 'Erin_Grall': [0, 0, 0, 0, 0, 1, 0, 0], 'Danielle_Tallafuss': [0, 0, 0, 0, 0, 2, 0, 0], 'Florida_Constitution': [0, 0, 0, 0, 0, 1, 0, 0]}\n",
      "\n",
      "landslide\n",
      "entity -> array of attribution counts for \n",
      "'Al Jazeera', 'Breitbart', 'CNN', 'Fox', 'Huffington Post', 'NYT', 'WSJ', 'Washington Times'\n",
      "{'Serhan_Aktoprak': [2, 3, 0, 0, 6, 0, 0, 6], 'Justine_McMahon': [2, 0, 0, 0, 0, 0, 0, 0], 'James_Marape': [0, 0, 0, 2, 0, 0, 0, 0], 'Barrick_Gold': [0, 0, 0, 1, 0, 0, 0, 0]}\n",
      "\n",
      "trump_trial\n",
      "entity -> array of attribution counts for \n",
      "'Al Jazeera', 'Breitbart', 'CNN', 'Fox', 'Huffington Post', 'NYT', 'WSJ', 'Washington Times'\n",
      "{'Donald_Trump': [2, 1, 2, 11, 1, 4, 3, 3], 'Juan_Merchan': [1, 0, 0, 0, 0, 0, 0, 3], 'Alvin_Bragg': [3, 0, 2, 7, 0, 0, 2, 2], 'Michael_Cohen': [2, 0, 0, 2, 0, 0, 1, 0], 'Todd_Blanche': [2, 1, 1, 8, 0, 1, 1, 0], 'Melanie_Sloan': [3, 0, 0, 0, 0, 0, 0, 0], 'John_Hendren': [2, 0, 0, 0, 0, 0, 0, 0], 'Mike_Johnson': [3, 0, 1, 0, 0, 0, 0, 0], 'Donald_Trump_Jr': [2, 0, 0, 0, 0, 0, 0, 0], 'Michael_Tyler': [2, 0, 2, 3, 0, 0, 0, 0], 'Hope_Hicks': [0, 0, 0, 0, 0, 0, 1, 0], 'Joe_Biden': [0, 2, 1, 0, 0, 0, 0, 0], 'Keith_Gaddie': [0, 1, 0, 0, 0, 0, 0, 0], 'Joshua_Steinglass': [0, 0, 0, 5, 0, 2, 0, 0], 'Juan_M_Merchan': [0, 0, 0, 0, 3, 0, 0, 0], 'Stormy_Daniels': [0, 0, 0, 0, 0, 1, 0, 0], 'Susan_Hoffinger': [0, 0, 0, 0, 0, 3, 0, 0], 'Alvin_L_Bragg': [0, 0, 0, 0, 0, 3, 0, 0], 'Michael_D_Cohen': [0, 0, 0, 0, 0, 4, 0, 0]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Quote attribution across 7-8 articles \n",
    "for topic in article_collection:\n",
    "    attrib_dict = dict()  # Key = person instance; Value = count of quotes attributed to the person(s)\n",
    "    defGraph = f'dna:{topic}_default'\n",
    "    response = requests.get(f'http://127.0.0.1:5000/dna/v1/repositories/narratives?repository={topic}')\n",
    "    result = response.json()\n",
    "    narr_dict = dict()\n",
    "    for narrative in result['narratives']:\n",
    "        narr_dict[narrative['narrativeId']] = narrative['narrativeMetadata']['source']\n",
    "    for narr_id in narr_dict.keys():\n",
    "        narrGraph = f'dna:{topic}_{narr_id}'\n",
    "        query_results = conn.select(\n",
    "            attribution_query.replace('?narrGraph', narrGraph), content_type='application/sparql-results+json')\n",
    "        if 'results' in query_results and 'bindings' in query_results['results']:\n",
    "            bindings = query_results['results']['bindings']\n",
    "        else:\n",
    "            bindings = []\n",
    "        for binding in bindings:\n",
    "            if 'agent' not in binding:     # No quotations or no quotation attributions\n",
    "                continue\n",
    "            agent = binding['agent']['value'].split(':dna:')[1]\n",
    "            if 'label' in binding:\n",
    "                label = binding['label']['value']\n",
    "            else:\n",
    "                label = ''\n",
    "            count = int(binding['cnt']['value'])\n",
    "            if agent.startswith('Noun_') and label:\n",
    "                agent_name = label\n",
    "            else:\n",
    "                agent_name = agent\n",
    "            if agent_name in attrib_dict.keys():\n",
    "                count_array = attrib_dict[agent_name]\n",
    "            else:\n",
    "                count_array = [0, 0, 0, 0, 0, 0, 0, 0]    # Init new count array\n",
    "            count_array[sources.index(narr_dict[narr_id])] = count    # Should only be 1 count per agent per source\n",
    "            attrib_dict[agent_name] = count_array\n",
    "    print(topic)\n",
    "    print(\"entity -> array of attribution counts for \")\n",
    "    print(\"'Al Jazeera', 'Breitbart', 'CNN', 'Fox', 'Huffington Post', 'NYT', 'WSJ', 'Washington Times'\")\n",
    "    print(attrib_dict)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0b5a598",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T17:52:35.573832Z",
     "start_time": "2024-06-05T17:52:30.765656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fl_abortion\n",
      "source -> array of attribution counts for\n",
      "'Al Jazeera', 'Breitbart', 'CNN', 'Fox', 'Huffington Post', 'NYT', 'WSJ', 'Washington Times'\n",
      "{'Al Jazeera': (5, 12, 10), 'Wall Street Journal': (8, 12, 8), 'Breitbart': (8, 12, 11), 'Fox News': (8, 12, 9), 'Washington Times': (8, 12, 9), 'CNN': (5, 12, 9), 'Huffington Post': (8, 12, 8), 'New York Times': (8, 12, 12)}\n",
      "\n",
      "landslide\n",
      "source -> array of attribution counts for\n",
      "'Al Jazeera', 'Breitbart', 'CNN', 'Fox', 'Huffington Post', 'NYT', 'WSJ', 'Washington Times'\n",
      "{'Al Jazeera': (5, 10, 6), 'Breitbart': (5, 8, 7), 'Fox News': (3, 8, 4), 'Washington Times': (5, 10, 8), 'CNN': (5, 8, 6), 'Huffington Post': (5, 9, 8), 'New York Times': (5, 8, 6)}\n",
      "\n",
      "trump_trial\n",
      "source -> array of attribution counts for\n",
      "'Al Jazeera', 'Breitbart', 'CNN', 'Fox', 'Huffington Post', 'NYT', 'WSJ', 'Washington Times'\n",
      "{'Al Jazeera': (8, 9, 8), 'Wall Street Journal': (5, 9, 5), 'Breitbart': (6, 12, 7), 'Fox News': (5, 12, 8), 'Washington Times': (5, 8, 5), 'CNN': (5, 12, 6), 'Huffington Post': (3, 8, 5), 'New York Times': (8, 12, 8)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Average grade level\n",
    "for topic in article_collection:\n",
    "    grade_dict = dict()  # Key = source; Value = min, max and avg grade level for sentences from source\n",
    "    defGraph = f'dna:{topic}_default'\n",
    "    response = requests.get(f'http://127.0.0.1:5000/dna/v1/repositories/narratives?repository={topic}')\n",
    "    result = response.json()\n",
    "    narr_dict = dict()\n",
    "    for narrative in result['narratives']:\n",
    "        narr_dict[narrative['narrativeId']] = narrative['narrativeMetadata']['source']\n",
    "    for narr_id in narr_dict.keys():\n",
    "        narrGraph = f'dna:{topic}_{narr_id}'\n",
    "        query_results = conn.select(\n",
    "            grade_query.replace('?narrGraph', narrGraph), content_type='application/sparql-results+json')\n",
    "        if 'results' in query_results and 'bindings' in query_results['results']:\n",
    "            bindings = query_results['results']['bindings']\n",
    "        else:\n",
    "            bindings = []\n",
    "        for binding in bindings:\n",
    "            numbSentences = int(binding['cnt']['value'])\n",
    "            minimum = float(binding['min']['value'])\n",
    "            maximum = float(binding['max']['value'])\n",
    "            avg = float(binding['avg']['value'])\n",
    "            grade_dict[narr_dict[narr_id]] = round(minimum), round(maximum), round(avg) \n",
    "    print(topic)\n",
    "    print(\"source -> array of attribution counts for\")\n",
    "    print(\"'Al Jazeera', 'Breitbart', 'CNN', 'Fox', 'Huffington Post', 'NYT', 'WSJ', 'Washington Times'\")\n",
    "    print(grade_dict)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49a9fcbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T17:52:42.369326Z",
     "start_time": "2024-06-05T17:52:37.604042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fl_abortion\n",
      "source -> conservative, liberal, neutral appeal on scale 1-5 (5=most appeal)\n",
      "{'Al Jazeera': (2, 4, 3), 'Wall Street Journal': (2, 4, 3), 'Breitbart': (3, 3, 4), 'Fox News': (3, 2, 4), 'Washington Times': (5, 1, 3), 'CNN': (3, 3, 4), 'Huffington Post': (2, 4, 3), 'New York Times': (3, 3, 4)}\n",
      "\n",
      "Al Jazeera liberal\n",
      "Wall Street Journal liberal\n",
      "Breitbart neutral\n",
      "Fox News neutral\n",
      "Washington Times conservative\n",
      "CNN neutral\n",
      "Huffington Post liberal\n",
      "New York Times neutral\n",
      "\n",
      "landslide\n",
      "source -> conservative, liberal, neutral appeal on scale 1-5 (5=most appeal)\n",
      "{'Al Jazeera': (3, 4, 4), 'Breitbart': (3, 4, 4), 'Fox News': (3, 4, 4), 'Washington Times': (3, 4, 5), 'CNN': (3, 4, 5), 'Huffington Post': (3, 4, 4), 'New York Times': (3, 4, 5)}\n",
      "\n",
      "Al Jazeera liberal\n",
      "Al Jazeera neutral\n",
      "Breitbart liberal\n",
      "Breitbart neutral\n",
      "Fox News liberal\n",
      "Fox News neutral\n",
      "Washington Times liberal\n",
      "Washington Times neutral\n",
      "CNN liberal\n",
      "CNN neutral\n",
      "Huffington Post liberal\n",
      "Huffington Post neutral\n",
      "New York Times liberal\n",
      "New York Times neutral\n",
      "\n",
      "trump_trial\n",
      "source -> conservative, liberal, neutral appeal on scale 1-5 (5=most appeal)\n",
      "{'Al Jazeera': (2, 4, 3), 'Wall Street Journal': (2, 4, 3), 'Breitbart': (2, 4, 3), 'Fox News': (2, 4, 3), 'Washington Times': (2, 4, 3), 'CNN': (2, 4, 3), 'Huffington Post': (2, 4, 3), 'New York Times': (2, 4, 3)}\n",
      "\n",
      "Al Jazeera liberal\n",
      "Wall Street Journal liberal\n",
      "Breitbart liberal\n",
      "Fox News liberal\n",
      "Washington Times liberal\n",
      "CNN liberal\n",
      "Huffington Post liberal\n",
      "New York Times liberal\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Appeal\n",
    "for topic in article_collection:\n",
    "    appeal_dict = dict()  # Key = source instance; Value = conservative, liberal and neutral appeal\n",
    "    defGraph = f'dna:{topic}_default'\n",
    "    response = requests.get(f'http://127.0.0.1:5000/dna/v1/repositories/narratives?repository={topic}')\n",
    "    result = response.json()\n",
    "    narr_dict = dict()\n",
    "    for narrative in result['narratives']:\n",
    "        narr_dict[narrative['narrativeId']] = narrative['narrativeMetadata']['source']\n",
    "    for narr_id in narr_dict.keys():\n",
    "        defGraph = f'dna:{topic}_default'\n",
    "        query_results = conn.select(\n",
    "            appeal_query.replace('?defGraph', defGraph), content_type='application/sparql-results+json')\n",
    "        if 'results' in query_results and 'bindings' in query_results['results']:\n",
    "            bindings = query_results['results']['bindings']\n",
    "        else:\n",
    "            bindings = []\n",
    "        for binding in bindings:\n",
    "            narr_id = binding['narrative']['value'].split(':dna:Narrative_')[1]\n",
    "            conservative = int(binding['conserv']['value'])\n",
    "            liberal = int(binding['lib']['value'])\n",
    "            neutral = int(binding['neutral']['value'])\n",
    "            appeal_dict[narr_dict[narr_id]] = conservative, liberal, neutral\n",
    "    print(topic)\n",
    "    print(\"source -> conservative, liberal, neutral appeal on scale 1-5 (5=most appeal)\")\n",
    "    print(appeal_dict)\n",
    "    print()\n",
    "    \n",
    "    for key, value in appeal_dict.items():\n",
    "        conserv, lib, neutral = value\n",
    "        if conserv > 3:\n",
    "            print(key, 'conservative')\n",
    "        if lib > 3:\n",
    "            print(key, 'liberal')\n",
    "        if neutral > 3:\n",
    "            print(key, 'neutral')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ed387cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T17:52:51.120961Z",
     "start_time": "2024-06-05T17:52:45.977801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fl_abortion\n",
      "rhetorical device -> array of counts for \n",
      "'Al Jazeera', 'Breitbart', 'CNN', 'Fox', 'Huffington Post', 'NYT', 'WSJ', 'Washington Times'\n",
      "{'ad populum': [1, 1, 1, 0, 1, 2, 4, 1], 'exceptionalism': [3, 2, 3, 1, 2, 1, 2, 1], 'hyperbole': [2, 6, 6, 1, 4, 6, 2, 1], 'invective': [1, 0, 0, 0, 0, 0, 0, 0], 'pathos': [4, 10, 9, 1, 8, 6, 5, 2], 'expletive': [0, 0, 1, 0, 0, 0, 1, 0], 'paralipsis': [0, 2, 1, 0, 1, 1, 2, 0], 'ad hominem': [0, 1, 1, 0, 0, 0, 0, 0], 'loaded language': [0, 2, 0, 0, 1, 0, 0, 0]}\n",
      "\n",
      "landslide\n",
      "rhetorical device -> array of counts for \n",
      "'Al Jazeera', 'Breitbart', 'CNN', 'Fox', 'Huffington Post', 'NYT', 'WSJ', 'Washington Times'\n",
      "{'exceptionalism': [1, 0, 1, 0, 2, 0, 0, 0], 'hyperbole': [3, 3, 3, 1, 2, 1, 0, 4], 'pathos': [2, 4, 1, 4, 5, 2, 0, 7], 'paralipsis': [0, 0, 0, 0, 0, 1, 0, 0]}\n",
      "\n",
      "trump_trial\n",
      "rhetorical device -> array of counts for \n",
      "'Al Jazeera', 'Breitbart', 'CNN', 'Fox', 'Huffington Post', 'NYT', 'WSJ', 'Washington Times'\n",
      "{'ad hominem': [1, 0, 0, 0, 0, 8, 1, 1], 'exceptionalism': [3, 4, 6, 3, 0, 8, 6, 1], 'expletive': [1, 0, 0, 0, 0, 1, 1, 1], 'hyperbole': [3, 10, 6, 6, 2, 33, 7, 6], 'paralipsis': [1, 3, 0, 2, 1, 8, 4, 4], 'pathos': [4, 7, 7, 3, 3, 18, 7, 2], 'ad populum': [0, 1, 1, 0, 0, 0, 1, 0], 'invective': [0, 0, 0, 0, 0, 0, 1, 0], 'loaded language': [0, 3, 0, 1, 0, 12, 4, 2], 'ad baculum': [0, 0, 0, 0, 0, 1, 0, 1]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rhetorical devices in article\n",
    "# Note that only a subset of devices are queried\n",
    "for topic in article_collection:\n",
    "    devices_dict = dict()  # Key = rhetorical device; Value = array of counts across sentences by source\n",
    "    defGraph = f'dna:{topic}_default'\n",
    "    response = requests.get(f'http://127.0.0.1:5000/dna/v1/repositories/narratives?repository={topic}')\n",
    "    result = response.json()\n",
    "    narr_dict = dict()\n",
    "    for narrative in result['narratives']:\n",
    "        narr_dict[narrative['narrativeId']] = narrative['narrativeMetadata']['source']\n",
    "    for narr_id in narr_dict.keys():\n",
    "        narrGraph = f'dna:{topic}_{narr_id}'\n",
    "        query_results = conn.select(rhetorical_query.replace('?narrGraph', narrGraph), content_type='application/sparql-results+json')\n",
    "        if 'results' in query_results and 'bindings' in query_results['results']:\n",
    "            bindings = query_results['results']['bindings']\n",
    "        else:\n",
    "            bindings = []\n",
    "        for binding in bindings:\n",
    "            if 'device' not in binding:     # No devices used in that article\n",
    "                continue     \n",
    "            device = binding['device']['value']\n",
    "            count = int(binding['cnt']['value'])\n",
    "            if device in devices_dict.keys():\n",
    "                count_array = devices_dict[device]\n",
    "            else:\n",
    "                count_array = [0, 0, 0, 0, 0, 0, 0, 0]    # Init new count array\n",
    "            count_array[sources.index(narr_dict[narr_id])] = count    # Should only be 1 count per agent per source\n",
    "            devices_dict[device] = count_array\n",
    "    print(topic)\n",
    "    print(\"rhetorical device -> array of counts for \")\n",
    "    print(\"'Al Jazeera', 'Breitbart', 'CNN', 'Fox', 'Huffington Post', 'NYT', 'WSJ', 'Washington Times'\")\n",
    "    print(devices_dict)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c07e827",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T17:53:27.429805Z",
     "start_time": "2024-06-05T17:53:22.608135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fl_abortion\n",
      "rhetorical device -> array of counts in full quotes for \n",
      "'Al Jazeera', 'Breitbart', 'CNN', 'Fox', 'Huffington Post', 'NYT', 'WSJ', 'Washington Times'\n",
      "{'ad populum': [2, 1, 3, 0, 0, 0, 1, 0], 'exceptionalism': [1, 0, 1, 0, 1, 1, 0, 0], 'hyperbole': [1, 1, 4, 6, 3, 2, 0, 0], 'pathos': [5, 1, 8, 4, 7, 5, 2, 0], 'expletive': [0, 1, 1, 0, 0, 0, 1, 0], 'loaded language': [0, 0, 1, 1, 0, 0, 0, 0], 'paralipsis': [0, 0, 1, 1, 0, 1, 0, 0], 'ad hominem': [0, 0, 0, 0, 0, 1, 0, 0]}\n",
      "\n",
      "landslide\n",
      "rhetorical device -> array of counts in full quotes for \n",
      "'Al Jazeera', 'Breitbart', 'CNN', 'Fox', 'Huffington Post', 'NYT', 'WSJ', 'Washington Times'\n",
      "{'hyperbole': [2, 1, 0, 1, 2, 0, 0, 2], 'pathos': [1, 1, 0, 0, 4, 0, 0, 3], 'paralipsis': [0, 0, 0, 1, 0, 0, 0, 0]}\n",
      "\n",
      "trump_trial\n",
      "rhetorical device -> array of counts in full quotes for \n",
      "'Al Jazeera', 'Breitbart', 'CNN', 'Fox', 'Huffington Post', 'NYT', 'WSJ', 'Washington Times'\n",
      "{'ad populum': [2, 0, 1, 2, 1, 0, 0, 0], 'exceptionalism': [2, 1, 1, 5, 0, 1, 0, 1], 'expletive': [2, 0, 0, 2, 0, 0, 0, 0], 'hyperbole': [9, 2, 4, 11, 1, 2, 1, 2], 'loaded language': [2, 0, 0, 5, 0, 1, 2, 0], 'pathos': [10, 3, 5, 11, 2, 3, 3, 4], 'invective': [0, 0, 0, 1, 0, 0, 1, 0], 'ad hominem': [0, 0, 0, 2, 0, 0, 0, 0], 'paralipsis': [0, 0, 0, 4, 0, 1, 0, 0]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rhetorical devices in articles' quotes\n",
    "# Note that only a subset of devices are queried\n",
    "for topic in article_collection:\n",
    "    quote_devices_dict = dict()  # Key = rhetorical device; Value = array of counts across sentences by source\n",
    "    defGraph = f'dna:{topic}_default'\n",
    "    response = requests.get(f'http://127.0.0.1:5000/dna/v1/repositories/narratives?repository={topic}')\n",
    "    result = response.json()\n",
    "    narr_dict = dict()\n",
    "    for narrative in result['narratives']:\n",
    "        narr_dict[narrative['narrativeId']] = narrative['narrativeMetadata']['source']\n",
    "    for narr_id in narr_dict.keys():\n",
    "        narrGraph = f'dna:{topic}_{narr_id}'\n",
    "        query_results = conn.select(quote_rhetorical_query.replace('?narrGraph', narrGraph), content_type='application/sparql-results+json')\n",
    "        if 'results' in query_results and 'bindings' in query_results['results']:\n",
    "            bindings = query_results['results']['bindings']\n",
    "        else:\n",
    "            bindings = []\n",
    "        for binding in bindings:\n",
    "            if 'device' not in binding:     # No devices used in that article\n",
    "                continue     \n",
    "            device = binding['device']['value']\n",
    "            count = int(binding['cnt']['value'])\n",
    "            if device in quote_devices_dict.keys():\n",
    "                count_array = quote_devices_dict[device]\n",
    "            else:\n",
    "                count_array = [0, 0, 0, 0, 0, 0, 0, 0]    # Init new count array\n",
    "            count_array[sources.index(narr_dict[narr_id])] = count    # Should only be 1 count per agent per source\n",
    "            quote_devices_dict[device] = count_array\n",
    "    print(topic)\n",
    "    print(\"rhetorical device -> array of counts in full quotes for \")\n",
    "    print(\"'Al Jazeera', 'Breitbart', 'CNN', 'Fox', 'Huffington Post', 'NYT', 'WSJ', 'Washington Times'\")\n",
    "    print(quote_devices_dict)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9aced1a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T17:53:34.997092Z",
     "start_time": "2024-06-05T17:53:29.849434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fl_abortion\n",
      "source -> array of tuples of sentence offset, event, event trigger text\n",
      "\n",
      "Al Jazeera\n",
      "\n",
      "[(1, 'CommunicationAndSpeechAct', 'criticizes'), (1, 'DisagreementAndDispute', 'criticizes'), (1, 'LawAndPolicy', 'Florida Supreme Court decision'), (2, 'CommunicationAndSpeechAct', 'criticizes'), (2, 'DisagreementAndDispute', 'criticizes'), (3, 'IssuingAndPublishing', 'wrote'), (4, 'LawAndPolicy', '15-week abortion ban'), (4, 'LegalEvent', 'upholds'), (5, 'LawAndPolicy', '15-week abortion ban'), (5, 'RemovalAndRestriction', 'likely enables'), (6, 'CommunicationAndSpeechAct', 'signed'), (6, 'CommunicationAndSpeechAct', 'passed'), (6, 'LawAndPolicy', '15-week abortion ban'), (6, 'LegalEvent', 'signed'), (6, 'LegalEvent', 'passed'), (7, 'LawAndPolicy', '15-week abortion ban'), (7, 'Marriage', 'faced')]\n",
      "\n",
      "Wall Street Journal\n",
      "\n",
      "[(1, 'AchievementAndAccomplishment', 'may benefit'), (2, 'CommunicationAndSpeechAct', 'allows'), (2, 'LawAndPolicy', 'early pregnancy abortion ban'), (2, 'LegalEvent', 'allows'), (3, 'AchievementAndAccomplishment', 'broad abortion access'), (3, 'Change', 'to restore broad abortion access'), (3, 'LawAndPolicy', 'ballot measure'), (3, 'Marriage', 'approves'), (3, 'ReturnRecoveryAndRelease', 'to restore'), (4, 'MeetingAndEncounter', 'hosts'), (5, 'AchievementAndAccomplishment', 'benefits'), (5, 'AggressiveCriminalOrHostileAct', 'disadvantages'), (6, 'CommunicationAndSpeechAct', 'identifies'), (6, 'PoliticalEvent', 'identifies'), (7, 'AchievementAndAccomplishment', 'secure'), (7, 'Agreement', 'secure'), (7, 'End', 'seven consecutive referendum victories')]\n",
      "\n",
      "Breitbart\n",
      "\n",
      "[(1, 'IssuingAndPublishing', 'issues'), (1, 'LawAndPolicy', 'mixed abortion-related decisions'), (1, 'LegalEvent', 'issues'), (2, 'ArrestAndImprisonment', \"state's six-week abortion limit enforcement\"), (2, 'LegalEvent', 'enables'), (3, 'CommunicationAndSpeechAct', 'signed'), (3, 'End', '15-week abortion limit'), (4, 'Agreement', 'signed'), (4, 'CommunicationAndSpeechAct', 'signed'), (4, 'LawAndPolicy', 'Heartbeat Bill'), (5, 'Continuation', 'maintains'), (5, 'RemovalAndRestriction', 'maintains'), (5, 'RemovalAndRestriction', 'block'), (6, 'LegalEvent', 'rules'), (7, 'CommunicationAndSpeechAct', 'permits'), (7, 'LawAndPolicy', 'abortion ballot measure')]\n",
      "\n",
      "Fox News\n",
      "\n",
      "[(1, 'CommunicationAndSpeechAct', 'allows'), (1, 'LawAndPolicy', '15-week abortion ban'), (1, 'LegalEvent', 'upholds'), (1, 'PoliticalEvent', 'vote'), (2, 'CommunicationAndSpeechAct', \"Ashley Moody's ballot argument\"), (3, 'Change', \"court's revision of Florida privacy amendment\"), (3, 'CommunicationAndSpeechAct', 'appreciates'), (4, 'IssuingAndPublishing', 'wrote'), (5, 'AcquisitionPossessionAndTransfer', 'misleadingly expands'), (5, 'AcquisitionPossessionAndTransfer', 'abortion access'), (5, 'Change', 'amendment misleadingly expands abortion access'), (5, 'CommunicationAndSpeechAct', 'claims'), (5, 'DeceptionAndDishonesty', 'misleadingly expands'), (6, 'CommunicationAndSpeechAct', 'files'), (6, 'DisagreementAndDispute', 'opposes'), (6, 'LawAndPolicy', 'amendment'), (7, 'CommunicationAndSpeechAct', 'praises')]\n",
      "\n",
      "Washington Times\n",
      "\n",
      "[(1, 'LawAndPolicy', '15-week abortion ban'), (1, 'LegalEvent', 'upholds'), (2, 'AcquisitionPossessionAndTransfer', 'signed by Governor Ron DeSantis'), (2, 'CommunicationAndSpeechAct', 'approves'), (2, 'CommunicationAndSpeechAct', 'signed by Governor Ron DeSantis'), (2, 'LawAndPolicy', '15-week abortion ban'), (2, 'LegalEvent', 'approves'), (3, 'Avoidance', 'continues'), (3, 'Continuation', 'continues'), (4, 'Agreement', '2022 law confirmation'), (4, 'Avoidance', 'six-week ban activation delayed'), (4, 'DelayAndWait', 'six-week ban activation delayed'), (4, 'DelayAndWait', 'activation delayed'), (4, 'LawAndPolicy', '15-week abortion ban'), (4, 'LawAndPolicy', '2022 law'), (5, 'AcquisitionPossessionAndTransfer', 'seeking'), (5, 'Culture', 'abortion'), (5, 'Measurement', 'majority'), (6, 'FreedomAndSupportForHumanRights', 'abortion access'), (6, 'ImpactAndContact', 'impacts'), (6, 'RemovalAndRestriction', 'impacts')]\n",
      "\n",
      "CNN\n",
      "\n",
      "[(1, 'Agreement', 'allows'), (1, 'LawAndPolicy', 'six-week abortion ban'), (1, 'Marriage', 'enables'), (1, 'PoliticalEvent', 'fall vote'), (2, 'LawAndPolicy', 'six-week abortion ban'), (2, 'RemovalAndRestriction', 'activates'), (3, 'Change', 'effect'), (3, 'StartAndBeginning', 'will take effect'), (4, 'Agreement', 'approves'), (4, 'IssuingAndPublishing', 'approves'), (4, 'LawAndPolicy', 'Florida Amendment 4'), (5, 'Agreement', 'require'), (5, 'Agreement', '60% voter approval'), (5, 'Cognition', 'require'), (6, 'AcquisitionPossessionAndTransfer', 'abortion access'), (6, 'CommunicationAndSpeechAct', 'electoral debate'), (6, 'DisagreementAndDispute', 'provoke'), (6, 'PoliticalEvent', 'provoke'), (6, 'RemovalAndRestriction', 'tighten'), (7, 'Cognition', 'views')]\n",
      "\n",
      "Huffington Post\n",
      "\n",
      "[(1, 'CommunicationAndSpeechAct', 'allows'), (1, 'LawAndPolicy', '15-week abortion ban'), (1, 'LegalEvent', 'upholds'), (2, 'FreedomAndSupportForHumanRights', 'abortion care protection'), (3, 'CommunicationAndSpeechAct', 'reads'), (3, 'LawAndPolicy', 'the ruling'), (4, 'Continuation', 'continues'), (5, 'LegalEvent', 'sued'), (6, 'CommunicationAndSpeechAct', 'allowed'), (6, 'LawAndPolicy', '15-week abortion ban'), (6, 'LegalEvent', 'allowed'), (7, 'DisagreementAndDispute', 'criticizes'), (7, 'LawAndPolicy', '15-week abortion ban')]\n",
      "\n",
      "New York Times\n",
      "\n",
      "[(1, 'FreedomAndSupportForHumanRights', 'abortion rights'), (1, 'RemovalAndRestriction', 'limits'), (2, 'Change', 'on expanding abortion access'), (2, 'Cognition', 'to decide'), (2, 'CommunicationAndSpeechAct', 'permit'), (3, 'Agreement', 'approves'), (3, 'CommunicationAndSpeechAct', 'approves'), (3, 'LawAndPolicy', 'abortion amendment'), (3, 'PoliticalEvent', 'for November ballot'), (4, 'Cognition', 'reflect'), (4, 'PoliticalEvent', 'reflect'), (4, 'TroubleAndProblem', 'national struggle with abortion post-Roe reversal'), (5, 'LawAndPolicy', '15-week abortion ban'), (5, 'LegalEvent', 'upholds'), (6, 'LawAndPolicy', '15-week abortion ban'), (6, 'LegalEvent', 'enables'), (7, 'CommunicationAndSpeechAct', 'wrote'), (7, 'IssuingAndPublishing', 'wrote')]\n",
      "\n",
      "\n",
      "landslide\n",
      "source -> array of tuples of sentence offset, event, event trigger text\n",
      "\n",
      "Al Jazeera\n",
      "\n",
      "[(1, 'Change', 'increased death toll in Papua New Guinea'), (1, 'CommunicationAndSpeechAct', 'reports'), (1, 'Death', 'reports'), (2, 'Change', 'increased death toll in Papua New Guinea'), (2, 'CommunicationAndSpeechAct', 'reports'), (2, 'Death', 'reports'), (3, 'EnvironmentAndCondition', 'had been'), (4, 'CommunicationAndSpeechAct', 'said'), (5, 'CommunicationAndSpeechAct', 'added'), (5, 'EnvironmentAndCondition', 'is based'), (6, 'Change', 'death toll at 100 or more'), (6, 'CommunicationAndSpeechAct', 'reported'), (6, 'Death', 'reported'), (7, 'HealthAndDiseaseRelated', 'received'), (7, 'HealthAndDiseaseRelated', 'medical treatment'), (7, 'TroubleAndProblem', 'Six victims')]\n",
      "\n",
      "Breitbart\n",
      "\n",
      "[(1, 'AggressiveCriminalOrHostileAct', 'kills'), (1, 'Death', 'kills'), (2, 'AggressiveCriminalOrHostileAct', 'over 150 houses buried'), (2, 'CommunicationAndSpeechAct', 'reports'), (3, 'EnvironmentalOrEcologicalEvent', 'devastates'), (3, 'EnvironmentalOrEcologicalEvent', 'buries'), (4, 'CommunicationAndSpeechAct', 'said'), (5, 'AggressiveCriminalOrHostileAct', 'over 1,000 displaced, resources nearly destroyed'), (5, 'AggressiveCriminalOrHostileAct', 'reports'), (5, 'CommunicationAndSpeechAct', 'reports'), (6, 'EmotionalResponse', 'feared'), (6, 'EnvironmentalOrEcologicalEvent', 'feared'), (6, 'TroubleAndProblem', 'high disaster casualties'), (7, 'Change', 'increased'), (7, 'CommunicationAndSpeechAct', 'reports'), (7, 'Measurement', 'increased death toll due to underestimated population')]\n",
      "\n",
      "Fox News\n",
      "\n",
      "[(1, 'EnvironmentalOrEcologicalEvent', 'devastates'), (2, 'EnvironmentalOrEcologicalEvent', 'buried'), (3, 'Death', 'reaches'), (3, 'InclusionAttachmentAndUnification', 'including'), (4, 'CommunicationAndSpeechAct', 'reports'), (4, 'Death', 'reports'), (4, 'End', 'over 100 deaths'), (5, 'AidAndAssistance', 'attempts to save'), (5, 'Attempt', 'attempts to save'), (5, 'Death', 'perishes'), (6, 'CommunicationAndSpeechAct', 'shows'), (7, 'CommunicationAndSpeechAct', 'could be heard'), (7, 'ReadinessAndAbility', 'could be heard')]\n",
      "\n",
      "Washington Times\n",
      "\n",
      "[(1, 'Change', 'exceeds'), (1, 'Measurement', 'Death toll'), (2, 'CommunicationAndSpeechAct', 'reports'), (2, 'Death', 'reports'), (2, 'Measurement', 'Death toll'), (3, 'EnvironmentAndCondition', 'had been'), (3, 'Measurement', 'The previous estimate'), (4, 'CommunicationAndSpeechAct', 'told'), (5, 'CommunicationAndSpeechAct', 'reported'), (5, 'Death', 'reported'), (5, 'Measurement', 'death toll at 100 or more'), (6, 'AcquisitionPossessionAndTransfer', 'found'), (6, 'AidAndAssistance', 'joins'), (7, 'MovementTravelAndTransportation', 'relocate'), (7, 'ReturnRecoveryAndRelease', 'relocate')]\n",
      "\n",
      "CNN\n",
      "\n",
      "[(1, 'Death', 'feared dead'), (1, 'Measurement', 'over 670'), (2, 'AggressiveCriminalOrHostileAct', '150 houses buried in Yambali village'), (2, 'CommunicationAndSpeechAct', 'reports'), (2, 'EnvironmentalOrEcologicalEvent', 'buried'), (3, 'Cognition', 'revises'), (3, 'Measurement', 'death toll estimate'), (4, 'CommunicationAndSpeechAct', 'reports'), (4, 'IssuingAndPublishing', 'reports'), (4, 'Measurement', 'higher population estimates'), (5, 'RemovalAndRestriction', 'were displaced'), (5, 'RemovalAndRestriction', 'were evacuated'), (6, 'IssuingAndPublishing', 'reports'), (6, 'TroubleAndProblem', 'extreme risk from falling rocks, increased soil pressure'), (7, 'CommunicationAndSpeechAct', 'reports')]\n",
      "\n",
      "Huffington Post\n",
      "\n",
      "[(1, 'Change', 'exceeds'), (2, 'CommunicationAndSpeechAct', 'reports'), (2, 'Death', 'reports'), (2, 'Measurement', 'Death toll'), (3, 'EnvironmentAndCondition', 'had been'), (3, 'Measurement', 'The previous estimate'), (4, 'CommunicationAndSpeechAct', 'told'), (5, 'CommunicationAndSpeechAct', 'reported'), (5, 'Death', 'reported'), (5, 'Measurement', 'death toll at 100 or more'), (6, 'AcquisitionPossessionAndTransfer', 'donates'), (6, 'AidAndAssistance', 'donates'), (6, 'ReturnRecoveryAndRelease', 'recovery'), (6, 'TroubleAndProblem', 'Six victims'), (7, 'MovementTravelAndTransportation', 'relocate'), (7, 'ReturnRecoveryAndRelease', 'relocate')]\n",
      "\n",
      "New York Times\n",
      "\n",
      "[(1, 'AggressiveCriminalOrHostileAct', 'kills'), (1, 'Death', 'kills'), (1, 'Measurement', 'at least 670'), (2, 'AchievementAndAccomplishment', 'rescue efforts'), (2, 'Avoidance', 'disrupts'), (2, 'EnvironmentalOrEcologicalEvent', 'disrupts'), (3, 'CommunicationAndSpeechAct', 'reports'), (3, 'RemovalAndRestriction', 'abandoned'), (3, 'RemovalAndRestriction', 'displaced'), (5, 'Cognition', 'anticipate'), (5, 'TroubleAndProblem', 'high child fatalities under age 15'), (6, 'AidAndAssistance', 'aid'), (7, 'DistributionSupplyAndStorage', 'tarps and water'), (7, 'DistributionSupplyAndStorage', 'delivered'), (7, 'DistributionSupplyAndStorage', 'not food')]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trump_trial\n",
      "source -> array of tuples of sentence offset, event, event trigger text\n",
      "\n",
      "Al Jazeera\n",
      "\n",
      "[(1, 'LegalEvent', 'found guilty'), (2, 'DeceptionAndDishonesty', 'of a crime'), (2, 'LegalEvent', 'was convicted'), (3, 'LegalEvent', 'convicts'), (4, 'Cognition', 'deliberated for two days'), (4, 'CommunicationAndSpeechAct', 'summoned'), (4, 'LegalEvent', 'deliberated for two days'), (4, 'MeetingAndEncounter', 'summoned'), (5, 'LawAndPolicy', '34 felony charges'), (5, 'LegalEvent', 'faced'), (6, 'CommunicationAndSpeechAct', 'claim'), (6, 'DeceptionAndDishonesty', 'Donald Trump hid payments to influence election'), (6, 'DeceptionAndDishonesty', 'hid'), (6, 'PoliticalEvent', 'to influence election'), (7, 'MeetingAndEncounter', 'faces')]\n",
      "\n",
      "Wall Street Journal\n",
      "\n",
      "[(1, 'AggressiveCriminalOrHostileAct', '34 felonies'), (1, 'ArrestAndImprisonment', 'convicts'), (1, 'LegalEvent', 'convicts'), (2, 'AggressiveCriminalOrHostileAct', 'may jeopardize'), (2, 'PoliticalEvent', \"Donald Trump's 2024 presidential bid\"), (2, 'PoliticalEvent', 'may jeopardize'), (3, 'EnvironmentAndCondition', 'steady'), (3, 'Measurement', \"Donald Trump's poll numbers\"), (4, 'LawAndPolicy', 'on all counts'), (4, 'LegalEvent', 'convicts'), (5, 'LegalEvent', 'declares guilty'), (6, 'Agreement', \"judge's verification of verdict agreement\"), (6, 'CommunicationAndSpeechAct', 'observed'), (6, 'LawAndPolicy', 'verdict agreement'), (6, 'LegalEvent', \"judge's verification of verdict agreement\"), (7, 'BodilyAct', 'gripped'), (7, 'EmotionalResponse', 'flushed')]\n",
      "\n",
      "Breitbart\n",
      "\n",
      "[(1, 'AggressiveCriminalOrHostileAct', 'was convicted of'), (1, 'DeceptionAndDishonesty', 'crime'), (1, 'LegalEvent', 'was convicted of'), (2, 'LegalEvent', 'convicts'), (3, 'LawAndPolicy', 'probation'), (4, 'EnvironmentAndCondition', 'becomes'), (5, 'AggressiveCriminalOrHostileAct', 'against Joe Biden'), (5, 'Continuation', 'can continue'), (5, 'PoliticalEvent', 'campaign'), (5, 'ReadinessAndAbility', 'can continue'), (6, 'AggressiveCriminalOrHostileAct', 'defiance'), (6, 'CommunicationAndSpeechAct', 'voiced'), (7, 'CommunicationAndSpeechAct', 'claims'), (7, 'DeceptionAndDishonesty', 'innocence'), (7, 'DelayAndWait', 'defers'), (7, 'LawAndPolicy', 'to election day verdict')]\n",
      "\n",
      "Fox News\n",
      "\n",
      "[(1, 'ArrestAndImprisonment', 'was convicted'), (1, 'LegalEvent', 'was convicted'), (3, 'ArrestAndImprisonment', 'charges'), (3, 'LegalEvent', 'charges'), (3, 'Measurement', 'with 34 counts'), (4, 'Measurement', 'with 34 counts'), (5, 'LegalEvent', 'found'), (6, 'ArrestAndImprisonment', 'carries'), (6, 'LawAndPolicy', 'a maximum prison sentence of 4 years'), (7, 'LawAndPolicy', 'a maximum prison sentence of 4 years'), (7, 'LegalEvent', 'faces')]\n",
      "\n",
      "Washington Times\n",
      "\n",
      "[(1, 'LegalEvent', 'convicts'), (2, 'PoliticalEvent', 'to campaign'), (3, 'AggressiveCriminalOrHostileAct', 'all counts guilty'), (3, 'CommunicationAndSpeechAct', 'declares'), (3, 'EmotionalResponse', 'reacts'), (4, 'BodilyAct', 'looked straight ahead'), (4, 'EmotionalResponse', 'was stoic'), (5, 'CommunicationAndSpeechAct', 'held'), (6, 'LawAndPolicy', 'the verdict'), (6, 'LegalEvent', 'confirmed'), (7, 'CommunicationAndSpeechAct', 'typing furiously'), (7, 'EnvironmentAndCondition', 'is silent')]\n",
      "\n",
      "CNN\n",
      "\n",
      "[(1, 'LawAndPolicy', 'on 34 felony charges'), (1, 'LegalEvent', 'convicts'), (2, 'LegalEvent', 'was convicted'), (3, 'EnvironmentAndCondition', 'could be'), (3, 'PoliticalEvent', 'if re-elected'), (4, 'IssuingAndPublishing', 'was announced'), (4, 'LawAndPolicy', 'Verdict'), (5, 'Change', 'impact'), (5, 'Cognition', 'to determine'), (5, 'Measurement', 'to determine'), (6, 'CommunicationAndSpeechAct', 'criticizes'), (6, 'DisagreementAndDispute', 'criticizes'), (7, 'Attempt', 'vowed to continue fighting'), (7, 'CommunicationAndSpeechAct', 'said'), (7, 'Continuation', 'continue fighting'), (7, 'Continuation', 'to continue fighting'), (7, 'War', 'fighting')]\n",
      "\n",
      "Huffington Post\n",
      "\n",
      "[(1, 'MeetingAndEncounter', 'summoned'), (2, 'CommunicationAndSpeechAct', \"jury's next day deliberation\"), (2, 'DelayAndWait', 'schedules'), (3, 'CommunicationAndSpeechAct', 'animated chats'), (3, 'CommunicationAndSpeechAct', 'having animated chats'), (3, 'EmotionalResponse', 'looked upbeat'), (4, 'EnvironmentAndCondition', 'remained silent'), (5, 'CommunicationAndSpeechAct', 'signaled by keys jingling'), (5, 'MovementTravelAndTransportation', 'rushes out'), (6, 'EnvironmentAndCondition', 'was back on the bench'), (7, 'CommunicationAndSpeechAct', 'signed'), (7, 'CommunicationAndSpeechAct', 'Jury note')]\n",
      "\n",
      "New York Times\n",
      "\n",
      "[(1, 'AggressiveCriminalOrHostileAct', 'jeopardizing'), (1, 'ArrestAndImprisonment', 'was convicted'), (1, 'PoliticalEvent', \"Donald J. Trump's 2016 presidential campaign\"), (2, 'ImpactAndContact', 'impacts'), (2, 'PoliticalEvent', 'impacts'), (3, 'PoliticalEvent', 'reelection'), (4, 'AggressiveCriminalOrHostileAct', 'disrupt'), (4, 'Culture', 'national norms'), (4, 'EmotionalResponse', 'delight'), (5, 'AggressiveCriminalOrHostileAct', 'undermines'), (5, 'Culture', 'rule of law'), (5, 'DeceptionAndDishonesty', 'undermines'), (5, 'DisagreementAndDispute', 'challenges'), (5, 'LawAndPolicy', 'conviction'), (5, 'LegalEvent', 'challenges'), (6, 'EmotionalResponse', 'reacts stoically'), (6, 'EmotionalResponse', 'falls silent'), (7, 'CommunicationAndSpeechAct', 'addressed')]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Events noted in the first 7 sentences of each article\n",
    "for topic in article_collection:\n",
    "    events_dict = dict()  # Key = source; Value = array of tuples of the sentence offset, event type and its triggering text\n",
    "    defGraph = f'dna:{topic}_default'\n",
    "    response = requests.get(f'http://127.0.0.1:5000/dna/v1/repositories/narratives?repository={topic}')\n",
    "    result = response.json()\n",
    "    narr_dict = dict()\n",
    "    for narrative in result['narratives']:\n",
    "        narr_dict[narrative['narrativeId']] = narrative['narrativeMetadata']['source']\n",
    "    for narr_id in narr_dict.keys():\n",
    "        narrGraph = f'dna:{topic}_{narr_id}'\n",
    "        query_results = conn.select(event_query.replace('?narrGraph', narrGraph), content_type='application/sparql-results+json')\n",
    "        if 'results' in query_results and 'bindings' in query_results['results']:\n",
    "            bindings = query_results['results']['bindings']\n",
    "        else:\n",
    "            bindings = []\n",
    "        for binding in bindings:   \n",
    "            offset = int(binding['offset']['value'])\n",
    "            event_type = binding['eventType']['value'].split(':dna:')[1]\n",
    "            event_text = binding['eventText']['value']\n",
    "            if narr_dict[narr_id] in events_dict:\n",
    "                curr_list = events_dict[narr_dict[narr_id]]\n",
    "            else:\n",
    "                curr_list = []\n",
    "            curr_list.append((offset, event_type, event_text))\n",
    "            events_dict[narr_dict[narr_id]] = curr_list \n",
    "    print(topic)\n",
    "    print(\"source -> array of tuples of sentence offset, event, event trigger text\")\n",
    "    print()\n",
    "    for key, value in events_dict.items():\n",
    "        print(key)\n",
    "        print()\n",
    "        print(value)\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7097480a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.844px",
    "left": "1211px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
