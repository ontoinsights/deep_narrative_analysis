# Processing to create the Turtle rendering of the events for the sentences in a narrative
# The sentences are defined by their sentence dictionaries, which have the form:
#    'text': 'narrative_text',
#    'LOCS': ['location1', ...], 'TIMES': ['dates_or_times1', ...], 'EVENTS': ['event1', ...],
#    'subjects': [{'subject_text': 'subject_text', 'subject_type': 'type_such_as_SINGNOUN'},
#                 {'subject_text': 'Narrator', 'subject_type': 'example_FEMALESINGPERSON'}],
#    'verbs': [{'verb_text': 'verb_text', 'verb_lemma': 'verb_lemma', 'tense': 'tense_such_as_Past',
#               'preps': [{'prep_text': 'preposition_text',
#                          'prep_details': [{'detail_text': 'preposition_object', 'detail_type': 'type_eg_SINGGPE'}]}],
#                          # Preposition object may also have a preposition - for ex, 'with the aid of the police'
#                          # If so, following the 'detail_type' entry would be another 'preps' element
#                          'objects': [{'object_text': 'verb_object_text', 'object_type': 'type_eg_SINGNOUN'}]}]}]}]}]}

import copy
import logging
import uuid

from clean_turtle import create_using_details, create_verb_label, handle_environment_cleanup, \
    handle_event_state_idiosyncrasies, handle_xcomp_cleanup
from coreference_resolution import check_specific_match, check_nouns
from create_event_time_loc import get_location_iri_and_ttl, get_sentence_location, get_sentence_time
from idiom_processing import get_verb_processing, process_idiom_detail
from nlp import get_sentence_sentiment
from query_ontology_and_sources import check_emotion, get_noun_ttl, get_event_state_class
from utilities import empty_string, objects_string, preps_string, subjects_string, verbs_string, add_unique_to_array

ttl_prefixes = ['@prefix : <urn:ontoinsights:dna:> .', '@prefix dna: <urn:ontoinsights:dna:> .',
                '@prefix geo: <urn:ontoinsights:geonames:> .',
                '@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .']

query_emotion = 'prefix : <urn:ontoinsights:dna:> SELECT ?superClass WHERE { ' \
                'keyword rdfs:subClassOf+ :superClass }'

# Date processing is handled differently/separately
prep_to_predicate_for_locs = {'about': ':has_topic',
                              'at': ':has_location',
                              'from': ':has_origin',
                              'to': ':has_destination',
                              'in': ':has_location'}

# TODO: https://www.oxfordlearnersdictionaries.com/us/definition/english/of
#       of someone (possession), of something (part), of related to measurement (2 lbs of potatoes)
# TODO: near loc, on loc, https://www.oxfordlearnersdictionaries.com/us/definition/english/over_1, without x


def create_event_turtle(narr_gender: str, sentence_dicts: list) -> list:
    """
    Using the sentence dictionaries generated by the nlp_graph functions, create the Turtle
    rendering of the events.

    :param narr_gender: Either an empty string or one of the values, AGENDER, BIGENDER, FEMALE or MALE -
                        indicating the gender of the narrator
    :param sentence_dicts: An array of sentence dictionaries for a narrative
    :returns: A list of the Turtle statements
    """
    logging.info(f'Creating event Turtle')
    last_date = empty_string  # Track the last mentioned date/time/event
    # List of dates/times/specific events in the sentences
    processed_dates = []      # Track all dates/times/events mentioned in the Turtle to only define once
    last_loc = empty_string   # Track the last mentioned location
    # Track all locations mentioned in the Turtle to only define once
    processed_locs = dict()   # Keys are location strings and the values are their IRIs
    last_nouns = []    # List of tuples (noun text, type and IRI) from previous sentence - Used for coref resolution
    graph_ttl_list = ttl_prefixes
    for sent_dict in sentence_dicts:
        graph_ttl_list = ttl_prefixes
        sentence_text = sent_dict['text']
        if not sentence_text[0].isalnum():
            continue                # Parse can return a verb_text of punctuation or new line; Ignore this
        if sentence_text == 'New line':
            last_nouns = []         # Reset list of last_nouns (coref only selects from current paragraph)
            continue
        sent_keys = sent_dict.keys()
        new_loc = empty_string
        if 'LOCS' in sent_keys:
            new_loc = get_sentence_location(sent_dict, last_loc)
            if not last_loc:
                last_loc = new_loc
        if 'TIMES' in sent_keys or 'EVENTS' in sent_keys:
            # Format of last_date: ('before'|'after'|'') (PointInTime date)
            last_date, date_ttl = get_sentence_time(sent_dict, last_date, processed_dates)
            if date_ttl:
                graph_ttl_list.extend(date_ttl)
        subjects = []
        if subjects_string in sent_keys:
            # Get the subject nouns (text, type and IRI) in the sent_dictionary and
            #    if a pronoun, attempt to resolve co-references
            subjects = check_nouns(narr_gender, sent_dict, subjects_string, last_nouns)
        sentence_ttl_list = []
        # Processing below adds object details to this array
        all_objects = []
        # Get xcomp details - for ex, 'she loved to play with her sister' => 'love' is the root verb,
        #   'play' is the xcomp, and the overall processing is "xcomp > :love, play"
        # Note that 'play' has the prepositional details; So the verbs need to be handled together when dealing
        #   with the xcomp verb; Need a dictionary in case there is more than 1 xcomp verb
        xcomp_dict = dict()
        for verb in sent_dict[verbs_string]:
            if 'verb_processing' in verb.keys() and 'xcomp >' in verb['verb_processing']:
                xcomp_verb = verb['verb_processing'].split(', ')[1].split(')')[0]
                xcomp_dict[xcomp_verb] = verb['verb_processing']
                if not subjects and objects_string in verb.keys():
                    # No subject, so the sentence has a passive root verb and its 'subjects' are defined
                    #    in the sentence dictionary as the verb's objects
                    xcomp_dict[objects_string] = verb[objects_string]
        for verb in sent_dict[verbs_string]:
            objects = []   # Objects are unique to the verb
            sent_details = [sentence_text, sent_dict['offset'], empty_string, last_date, last_loc, new_loc]
            if 'verb_processing' in verb.keys() and 'xcomp >' in verb['verb_processing']:  # Is xcomp's ROOT verb
                # Can ignore the root verb since we have the xcomp processing
                continue
            if verb['verb_lemma'] in xcomp_dict.keys():    # Associate xcomp processing with the xcomp verb
                sent_details[2] = xcomp_dict[verb['verb_lemma']]
                if objects_string in xcomp_dict.keys():
                    xcomp_subjs = check_nouns(narr_gender, xcomp_dict, objects_string, last_nouns)
                    event_iri, new_ttl_list = process_sentence_verb(
                        narr_gender, sent_details, verb, True, xcomp_subjs, objects, last_nouns, processed_locs)
                else:
                    event_iri, new_ttl_list = process_sentence_verb(
                        narr_gender, sent_details, verb, False, subjects, objects, last_nouns, processed_locs)
            else:
                event_iri, new_ttl_list = process_sentence_verb(
                    narr_gender, sent_details, verb, False, subjects, objects, last_nouns, processed_locs)
            if objects:
                all_objects.extend(objects)   # Retain all objects, since they are associated with the verb
            sentence_ttl_list.extend(new_ttl_list)
        graph_ttl_list.extend(sentence_ttl_list)
        # Update last_nouns to all the subjects/objects of the sentence
        add_unique_to_array(all_objects, subjects)   # Add objects -> subjects
        last_nouns = copy.deepcopy(subjects)     # Reset last_nouns to the nouns from the current sentence
        # Update the last_loc
        if new_loc:
            last_loc = new_loc
    # Finished with all the sentences
    return graph_ttl_list


# Functions internal to the module but accessible to testing
def create_ttl_for_prep_detail(prep_details: list, prepositions: list, event_iri: str, narr_gender: str,
                               last_nouns: list, processed_locs: dict, sentence_text: str, turtle: list) -> list:
    """
    Parse the details for a verb's prepositions and create the corresponding Turtle. Note that
    dates/times are not handled in this code, but for the sentence overall (in create_event_turtle).

    :param prep_details: A list of tuples holding the preposition text, its object text
                         and object type
    :param prepositions: Array of tuples of the preposition text and its object text, type and IRI
                         (This array may be updated in this function)
    :param event_iri: The IRI for the verb/event
    :param narr_gender: Either an empty string or one of the values, AGENDER, BIGENDER, FEMALE or MALE -
                        indicating the gender of the narrator
    :param last_nouns: A list of all noun text, type and IRI tuples
    :param processed_locs: A dictionary of location texts (keys) and their IRI (values) of
                           all locations already processed
    :param sentence_text: The full text of the sentence (needed for checking for idioms)
    :param turtle: The current Turtle rendering of the sentence to which the preposition object
                   details are added
    :returns: An array holding the tuples for the preposition and its object
    """
    prep_turtle = []
    for prep_text, obj_text, obj_type in prep_details:
        # Check for match of existing ontology concepts
        match_iri, match_type = check_specific_match(obj_text, obj_type)
        if match_iri:    # Already have the noun/concept defined
            prep_turtle.append(f'{event_iri} {prep_to_predicate_for_locs[prep_text]} {match_iri} .')
            prepositions.append((prep_text, obj_text, obj_type, match_iri))
            continue
        # Or match a location
        if obj_type.endswith('GPE') or obj_type.endswith('LOC'):
            # Get location details and add the corresponding Turtle
            loc_iri, loc_ttl = get_location_iri_and_ttl(obj_text, processed_locs)
            if loc_ttl:
                prep_turtle.extend(loc_ttl)
            prep_turtle.append(f'{event_iri} {prep_to_predicate_for_locs[prep_text]} {loc_iri} .')
            prepositions.append((prep_text, obj_text, obj_type, loc_iri))
            continue
        # Resolve any co-reference and get object's IRI (from check_nouns)
        prep_dict = {'objects': [{'object_text': obj_text,
                                  'object_type': obj_type}]}
        obj_text, obj_type, obj_iri = check_nouns(narr_gender, prep_dict, objects_string, last_nouns)[0]
        noun_ttl = get_noun_ttl(obj_iri, obj_text, obj_type, sentence_text, last_nouns, processed_locs)
        if noun_ttl:
            prep_turtle.extend(noun_ttl)
        prepositions.append((prep_text, obj_text, obj_type, obj_iri))
        noun_str = str(noun_ttl)
        # Relationships for an Agent are different from associations for other "things"
        if ':Person' in noun_str or 'Agent' in noun_str or ':Organization' in noun_str:
            if prep_text == 'from':
                prep_turtle.append(f'{event_iri} :has_provider {obj_iri} .')
            elif prep_text == 'to':
                prep_turtle.append(f'{event_iri} :has_recipient {obj_iri} .')
            elif prep_text == 'for':
                prep_turtle.append(f'{event_iri} :has_affected_agent {obj_iri} .')
            elif prep_text == 'with':
                prep_turtle.append(f'{event_iri} :has_active_agent {obj_iri} .')
        elif not (f' {obj_iri} .' in noun_str or f' {obj_iri} ;' in noun_str):  # Object already accounted for
            if prep_text == 'with':
                prep_turtle.append(f'{event_iri} :has_instrument {obj_iri} .')
            elif prep_text in prep_to_predicate_for_locs.keys() and \
                    (':Location' in noun_str or obj_type.endswith('LOC')):
                prep_turtle.append(f'{event_iri} {prep_to_predicate_for_locs[prep_text]} {obj_iri} .')
            elif prep_text in ('about', 'from', 'in', 'of', 'to'):
                prep_turtle.append(f'{event_iri} :has_topic {obj_iri} .')
    if prep_turtle:
        turtle.extend(prep_turtle)
    return prep_turtle


def get_preposition_tuples(prep_dict: dict) -> list:
    """
    Extracts the details from the preposition dictionary of a verb.

    :param prep_dict: A dictionary holding the details for a single preposition for a verb
                      For example, "{'prep_text': 'with', 'prep_details': [{'detail_text': 'other children',
                      'detail_type': 'PLURALNOUN'}]}"
    :returns: An array holding tuples consisting of the preposition text, and the preposition's object
             text and type
    """
    prep_details = []
    if 'prep_details' in prep_dict.keys():
        for prep_detail in prep_dict['prep_details']:
            if 'detail_text' in prep_detail.keys():
                prep_detail_type = prep_detail['detail_type']   # If there is _text, there will also be _type
                if prep_detail_type.endswith('DATE') or prep_detail_type.endswith('TIME') or  \
                        prep_detail_type.endswith('EVENT'):
                    # Time-related - so, this is already handled => ignore
                    continue
                prep_details.append((prep_dict['prep_text'].lower(), prep_detail['detail_text'], prep_detail_type))
    return prep_details


def process_aux_verb(verb_dict: dict, sent_text: str) -> (str, str):
    """
    Determines whether the auxiliary verb defines an emotion or mood - which affects the overall
    definition and sentiment of the sentence.

    :param verb_dict: The dictionary for the verb
    :param sent_text: Text of the sentence (used only for logging purposes)
    :returns: A tuple holding two strings - the emotion or mood text and class name if appropriate
               for the auxiliary verb ; Otherwise, two empty strings
    """
    aux_label = empty_string
    emotion = empty_string
    if 'verb_aux' in verb_dict.keys():
        aux_label = verb_dict['verb_aux']
        if aux_label == 'to':
            aux_label = empty_string
        else:
            # Determine if the first verb is an emotion or mood by getting the Event/State class for the text
            aux_verb_class = get_event_state_class(aux_label)
            emotion = check_emotion(aux_verb_class)
            if not emotion:
                logging.warning(f'Found aux verb that was not "be"/"have"/"did" or an emotion, {sent_text}')
    return aux_label, emotion


def process_event_date(sent_text: str, event_iri: str, last_date: str, ttl_list: list):
    """
    Creates the Turtle for an event's date.

    :param sent_text: The text of the sentence being processed
    :param event_iri: IRI identifying the event
    :param last_date: A string holding the date text
    :param ttl_list: An array of the Turtle statements for the event (updated in this function)
    :returns: None (ttl_list is updated)
    """
    date_iri = f":{last_date.split(':')[1]}"   # Format of last_date: ('before'|'after'|'') (PointInTime date)
    if last_date.startswith('before'):
        ttl_list.append(f'{event_iri} :has_latest_end {date_iri} .')
    elif last_date.startswith('after') or 'eventually' in sent_text.lower() \
            or 'afterwards' in sent_text.lower() or 'finally' in sent_text.lower():
        ttl_list.append(f'{event_iri} :has_earliest_beginning {date_iri} .')
    else:
        ttl_list.append(f'{event_iri} :has_time {date_iri} .')
    return


def process_sentence_verb(narr_gender: str, sentence_details: list, verb_dict: dict, is_xcomp_subjects: bool,
                          subjects: list, objects: list, last_nouns: list, processed_locs: dict) -> (str, list):
    """
    Generate the Turtle for the root event/verb of the sentence, based on the details for the verb
    in the sentence dictionary.

    :param narr_gender: Either an empty string or one of the values, AGENDER, BIGENDER, FEMALE or MALE -
                        indicating the gender of the narrator
    :param sentence_details: An array holding the strings, sentence_text (index 0), offset (index 1),
                             xcomp_processing idiom rule (index 2), last_date (index 3), last_loc (index 4)
                             and new_loc (index 5)
    :param verb_dict: The verb details from the sentence dictionary
    :param is_xcomp_subjects: Boolean indicating that the subjects come from the root verb, which is passive
    :param subjects: Array of tuples that are the subject text, type and IRI
    :param objects: Array of tuples that are the object text, type and IRI (This array is updated
                    by the verb's object and prepositional objects' information)
    :param last_nouns: A list of all noun text, type and IRI tuples that is used for co-reference resolution
                       (it is updated with new nouns from the verb prepositions)
    :param processed_locs: A dictionary of location texts (keys) and their IRI (values) of
                           all locations already processed
    :returns: A tuple with 1) a string that is the event IRI and 2) a list of Turtle statements describing
             the event (Also, the objects array may be updated)
    """
    logging.info(f'Processing verb, {verb_dict["verb_lemma"]}')
    sentence_text = sentence_details[0]
    ttl_list = []
    event_iri = f':Event_{str(uuid.uuid4())[:13]}'
    ttl_list.append(f'{event_iri} :text "{sentence_text}" ; :sentence_offset {sentence_details[1]} .')
    negated = False
    if 'negation' in verb_dict.keys():
        negated = True
        ttl_list.append(f'{event_iri} :negation true .')
    process_event_date(sentence_text, event_iri, sentence_details[3], ttl_list)    # Process the date of the event
    # Have subject details already; Get object details
    if objects_string in verb_dict.keys():
        # Check previous and current sentence nouns
        add_unique_to_array(check_nouns(narr_gender, verb_dict, objects_string, last_nouns), objects)
    # Create TTL for the subject/object nouns
    _process_subjects_and_objects(subjects, sentence_text, ttl_list, last_nouns, processed_locs)
    _process_subjects_and_objects(objects, sentence_text, ttl_list, last_nouns, processed_locs)
    # Get and process the prepositions and their objects
    prepositions = []        # List of tuples (preposition text, object text, object type, object IRI)
    prep_ttl = []            # Expediency for idiom processing
    if preps_string in verb_dict.keys():
        for prep_dict in verb_dict[preps_string]:
            prep_details = get_preposition_tuples(prep_dict)  # An array of tuples of the prep and object text/type
            # Get IRI and add Turtle for the object (if new)
            if prep_details:
                prep_ttl.extend(create_ttl_for_prep_detail(prep_details, prepositions, event_iri, narr_gender,
                                                           last_nouns, processed_locs, sentence_text, ttl_list))
    # Map verbs and related details to the ontology - Starting with idioms
    if sentence_details[2]:
        processing = [sentence_details[2]]
    elif 'verb_processing' in verb_dict.keys():
        processing = [verb_dict['verb_processing']]
    else:
        processing = get_verb_processing(verb_dict)
    # Either parse the idiom or try to match the event/state to the semantics of the ontology classes
    xcomp_label = empty_string    # Another xcomp expediency
    if processing:
        event_state_ttl = process_idiom_detail(processing, sentence_text, verb_dict, prepositions)
        if 'xcomp' in str(event_state_ttl):
            xcomp_label = event_state_ttl[0].split('(')[1].split(')')[0]
            if ', ' in xcomp_label:
                xcomp_label = xcomp_label.replace(',', ' to')
        for es_ttl in event_state_ttl:
            es_ttl = f'{event_iri} a {es_ttl}'
            ttl_list.append(
                handle_event_state_idiosyncrasies(es_ttl, sentence_text, verb_dict, subjects, objects, prepositions))
    else:
        event_state_ttl = get_event_state_class(verb_dict['verb_lemma'])
        ttl_list.append(f'{event_iri} a {event_state_ttl} .')
    aux_label, aux_emotion = process_aux_verb(verb_dict, sentence_text)
    # TODO: If emotion, then treat as xcomp and aux_emotion affects sentiment
    # Get the origin for a MovementTravelAndTransportation event
    # Origin is the location defined by the preposition 'from' OR the last location/from the previous sentence
    ttl_str = str(ttl_list)
    if ':Movement' in ttl_str and preps_string in verb_dict.keys() and "'from'" not in str(verb_dict[preps_string]):
        loc_iri, loc_ttl = get_location_iri_and_ttl(sentence_details[4], processed_locs)
        # Will use the location returned, and that Turtle is already defined - no need to use loc_ttl
        ttl_list.append(f'{event_iri} :has_origin {loc_iri} .')
    verb_label = verb_dict['verb_text']
    # Special case for the word, 'using'
    using_label = create_using_details(verb_dict, event_iri, sentence_text, ttl_list, last_nouns, processed_locs)
    # Final cleanup/completion of semantics
    # No need to reset the ttl_str, advcl changes are not relevant to the following check
    if processing and 'EnvironmentAndCondition' in ttl_str:
        ttl_list = handle_environment_cleanup(ttl_list, objects)
    if not processing or (processing and 'subj >' not in processing[0]):
        # Add detail about subjects/objects for everything BUT subj_rules (which already deal with them)
        for subj_text, subj_type, subj_iri in subjects:
            if ':Affiliation' in str(event_state_ttl):
                ttl_list.append(f'{event_iri} :affiliated_agent {subj_iri} .')
            else:
                ttl_list.append(f'{event_iri} :has_active_agent {subj_iri} .')
        for obj_text, obj_type, obj_iri in objects:
            if not (f'agent {obj_iri}' in ttl_str or f'with {obj_iri}' in ttl_str
                    or f'topic {obj_iri}' in ttl_str):
                if 'PERSON' in obj_type or obj_type.endswith('GPE') or obj_type.endswith('ORG') \
                     or obj_type.endswith('NORP'):
                    if ':Affiliation' in str(event_state_ttl):
                        ttl_list.append(f'{event_iri} :affiliated_with {obj_iri} .')
                    else:
                        ttl_list.append(f'{event_iri} :has_affected_agent {obj_iri} .')
                else:
                    ttl_list.append(f'{event_iri} :has_topic {obj_iri} .')
    # Make sure that there is a location
    location_ttl = f'{event_iri} :location'
    if not (location_ttl.replace('location', 'has_location') in ttl_str or
            location_ttl.replace('location', 'has_origin') in ttl_str or
            location_ttl.replace('location', 'has_destination') in ttl_str):
        # No location from the sentence dictionary, so use/persist the last location
        # That Turtle is already defined - no need to check loc_ttl
        if sentence_details[5]:
            loc_iri, loc_ttl = get_location_iri_and_ttl(sentence_details[5], processed_locs)
        else:
            loc_iri, loc_ttl = get_location_iri_and_ttl(sentence_details[4], processed_locs)
        ttl_list.append(f'{event_iri} :has_location {loc_iri} .')
    # Finish up by adding the label and sentiment and doing final xcomp cleanup
    labels = [verb_label, xcomp_label, using_label, aux_label]
    ttl_list.append(f'{event_iri} rdfs:label '
                    f'"{create_verb_label(labels, subjects, objects, prepositions, negated).strip()}" .')
    # TODO: How does negation affect the sentiment?
    ttl_list.append(f'{event_iri} :sentiment {get_sentence_sentiment(sentence_text)} .')
    if xcomp_label:
        ttl_list = handle_xcomp_cleanup(ttl_list, event_iri, subjects, is_xcomp_subjects)
    # Lastly, add the prepositional objects to the objects array (which is then added to last_nouns)
    prep_objs = []
    for prep_text, prep_obj_text, prep_obj_type, prep_obj_iri in prepositions:
        prep_objs.append((prep_obj_text, prep_obj_type, prep_obj_iri))
    add_unique_to_array(prep_objs, objects)
    return event_iri, ttl_list


# Functions internal to the module
def _process_subjects_and_objects(nouns: list, sentence_text: str, turtle: list,
                                  last_nouns: list, processed_locs: dict):
    """
    Iterates through each of the noun tuples and either matches their text to a domain concept or
    creates the appropriate Turtle to describe their semantics. As part of the Turtle definition, an
    IRI identifying the noun is created.
    
    :param nouns: Array of tuples that are the noun text, type and IRI for subjects or objects
    :param sentence_text: The raw text of the sentence being processed
    :param turtle: The current array of Turtle statements (which is updated in this function, if the
                   noun is 'new' (not already defined in the domain)
    :param last_nouns: A list of all noun text, type and IRI tuples
    :param processed_locs: A dictionary of location texts (keys) and their IRI (values) of
                           all locations already processed
    :returns: None
    """
    for noun in nouns:
        noun_text, noun_type, noun_iri = noun
        # Check for the noun_iri in last_nouns or the current TTL
        if f'{noun_iri} a ' in str(turtle):
            return
        noun_ttl = get_noun_ttl(noun_iri, noun_text, noun_type, sentence_text, last_nouns, processed_locs)
        if noun_ttl:
            turtle.extend(noun_ttl)
    return
