{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08620299-a2ec-4044-ab6d-3a4956487da6",
   "metadata": {},
   "source": [
    "# Gather background data on the Holocaust \n",
    "## Dates, people, places and events\n",
    "\n",
    "Material is extracted from the glossary page of the United States Holocaust Memorial Museum, https://www.ushmm.org/. \n",
    "    \n",
    "The page was downloaded as a flat HTML file, and processed using the code below.\n",
    "\n",
    "Due to the difficulties in correctly sub-classing noun types, an interactive spreadsheet is used in this notebook ... for the ontologist to insert the appropriate superclasses and to indicate if a term is a type or instance.\n",
    "\n",
    "Note that this notebook must be executed in Jupyter Notebook (vs JupyterLab due to problem with qgrid in JupyterLab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10ce9445-7d58-46e0-a1a1-8238f7b22da7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T22:02:01.385456Z",
     "start_time": "2021-04-15T22:02:01.098443Z"
    }
   },
   "outputs": [],
   "source": [
    "## Imports\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import pandas as pd\n",
    "import qgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b974c390-3111-4d2a-b90a-120500f56319",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T22:02:04.870038Z",
     "start_time": "2021-04-15T22:02:04.867425Z"
    }
   },
   "outputs": [],
   "source": [
    "## Constants\n",
    "ttl_prefix = '@prefix : <urn:ontoinsights:ontology:dna:> . \\n'\\\n",
    "             '@prefix dna: <urn:ontoinsights:ontology:dna:> . \\n'\\\n",
    "             '@prefix owl: <http://www.w3.org/2002/07/owl#> . \\n'\\\n",
    "             '@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> . \\n'\\\n",
    "             '@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> . \\n'\\\n",
    "             '@prefix xsd: <http://www.w3.org/2001/XMLSchema#> . \\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29cc633a-1f72-445d-aa1e-bc5baf8eaed0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T23:13:12.484918Z",
     "start_time": "2021-04-15T23:13:12.480707Z"
    }
   },
   "outputs": [],
   "source": [
    "def fix_up_name(text: str) -> (str, str):\n",
    "    \"\"\"\n",
    "    Fix the word(s) that will become the class name to remove quotation marks, be upper camel-cased, \n",
    "    handle parentheses and commas, and remove spaces.\n",
    "    \n",
    "    The input parameter is the text that will become the class name.\n",
    "    The output parameter is the 'label' for the text.\n",
    "    \"\"\"\n",
    "    \n",
    "    label = text.replace('\"', '')   # Remove quotation marks\n",
    "    label = label.replace('“', '')\n",
    "    label = label.replace('”', '')\n",
    "    label = label.title()  # Upper camel-cased\n",
    "\n",
    "    if '(' in label:\n",
    "        paren_index = label.find('(') \n",
    "        class_name = label[0:paren_index].strip()    # Get rid of anything after parentheses\n",
    "        label_text = f'{label[0:paren_index]}; {label[paren_index + 1:label.find(')')]}'\n",
    "    else:\n",
    "        class_name = label\n",
    "        label_text = label\n",
    "    class_name = class_name.replace(',', '')   # Remove commas\n",
    "    class_name = class_name.replace(' ', '')   # Remove spaces\n",
    "    return class_name, label_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "457be338-9b82-4362-a2fe-40eeaa8aa429",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T23:13:14.719961Z",
     "start_time": "2021-04-15T23:13:14.625593Z"
    }
   },
   "outputs": [],
   "source": [
    "# Process the glossary\n",
    "with open('Glossary _ Holocaust Encyclopedia.html', 'r') as gloss_in:\n",
    "    gloss_page = gloss_in.read()\n",
    "    \n",
    "soup = BeautifulSoup(gloss_page, 'html.parser')\n",
    "terms = soup.find('div', {'class': 'article-main-text'})\n",
    "# print(terms) results are:\n",
    "# <div class=\"article-main-text\" id=\"story-text\">\n",
    "# <p><strong><a href=\"/narrative/3225/en\">Antisemitism</a>:</strong> hostility toward or hatred of Jews as a religious or ethnic group, often accompanied by social, economic, or political discrimination.</p>\n",
    "# <p><strong><em>Appellplatz</em>:</strong> German word for roll call square where prisoners were forced to assemble.</p>\n",
    "# ...\n",
    "# </div>\n",
    "\n",
    "# Create lists of glossary terms, their labels and their definitions\n",
    "gloss_terms = list()\n",
    "gloss_labels = list()\n",
    "gloss_defns = list()\n",
    "gloss = ''\n",
    "for term in terms.find_all('p'):\n",
    "    found_colon = term.get_text().find(':', 0, term.find('</strong>'))\n",
    "    if found_colon > 0:\n",
    "        # Colon indicates that there is a new term being defined\n",
    "        # Save the info\n",
    "        if gloss:\n",
    "            gloss_terms.append(gloss)\n",
    "            gloss_labels.append(label)\n",
    "            gloss_defns.append(new_defn)\n",
    "        text = term.get_text().split(':')\n",
    "        gloss, label = fix_up_name(text[0]) \n",
    "        defn = text[1].strip()\n",
    "        # Make sure that the first character of the defn is upper case and that double quotes are escaped\n",
    "        new_defn = (defn[0].upper() + defn[1:]).replace('\"', '\\\\\"')\n",
    "    else:\n",
    "        # Another paragraph but not a new term\n",
    "        defn = term.get_text().replace('\"', '\\\\\"')\n",
    "        new_defn += defn\n",
    "# When finished, write out the last term\n",
    "gloss_terms.append(gloss)\n",
    "gloss_labels.append(label)\n",
    "gloss_defns.append(new_defn)\n",
    "    \n",
    "# Turn the lists into a dataframe \n",
    "dict = {'Term': gloss_terms, 'Label': gloss_labels, 'Defn': gloss_defns} \n",
    "gloss_df = pd.DataFrame(dict)\n",
    "# Add columns to be hand-edited (using qgrid, next)\n",
    "gloss_df['Superclass'] = ''\n",
    "gloss_df['IsInstance'] = 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab2a7a77-04f9-4368-b79c-9a1fcdf41825",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T23:13:17.296022Z",
     "start_time": "2021-04-15T23:13:17.275120Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6467d80d59f4e80bafb4e686fffd8a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To run qgrid, need to 1) import it and 2) have executed:\n",
    "#   jupyter nbextension enable --py --sys-prefix qgrid\n",
    "#   jupyter nbextension enable --py --sys-prefix widgetsnbextension # only required if you have not enabled the ipywidgets nbextension yet\n",
    "# Currently qgrid does not work in JupyterLab 3 \n",
    "\n",
    "# QGrid is used to add superclass and instance info for the new concepts\n",
    "# Also, used to fix up any acronyms (e.g., 'SS') since they are not capitalized correctly due to .title()\n",
    "# And, added synonyms from the text to the labels (will be done automatically later)\n",
    "grid_widget = qgrid.show_grid(gloss_df, show_toolbar=True)\n",
    "grid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ae89128",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T17:24:33.181737Z",
     "start_time": "2021-04-16T17:24:33.175690Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Term                                 Label  \\\n",
      "25  Kristallnacht  Kristallnacht; Night of Broken Glass   \n",
      "\n",
      "                                                 Defn   Superclass IsInstance  \n",
      "25  Usually referred to as the \\\"Night of Broken G...  PointInTime       True  \n"
     ]
    }
   ],
   "source": [
    "updated_gloss = grid_widget.get_changed_df()\n",
    "print(updated_gloss.iloc[[25]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c02c1ba5-d562-4258-a2cc-9e0bbe358dd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T17:25:30.321015Z",
     "start_time": "2021-04-16T17:25:30.310276Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write out the dataframe as turtle\n",
    "with open('holocaust-gloss.ttl', 'w') as gloss_out:\n",
    "    # Write the prefix details\n",
    "    gloss_out.write(ttl_prefix)\n",
    "    # Write out each gloss term\n",
    "    for index, row in updated_gloss.iterrows():\n",
    "        superclass_text = row['Superclass']\n",
    "        if superclass_text == 'XXX':  # Term will be addressed manually\n",
    "            continue\n",
    "        if ',' in superclass_text:\n",
    "            superclass_text = superclass_text.replace(', ', ', :')\n",
    "        term_text = row['Term']\n",
    "        label_text = row['Label']\n",
    "        if ';' in label_text:\n",
    "            label_text = label_text.replace('; ', '\", \"')    \n",
    "        defn_text = row['Defn']\n",
    "        instance_text = row['IsInstance']\n",
    "        if instance_text == 'True':\n",
    "            gloss_out.write(f':{term_text} a :{superclass_text} ;\\n')\n",
    "        else:  \n",
    "            gloss_out.write(f':{term_text} a owl:Class ;\\n  rdfs:subClassOf :{superclass_text} ;\\n')\n",
    "        gloss_out.write(f'  rdfs:label \"{label_text}\" ;\\n  :defn \"{defn_text}\" .\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ecf24fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T18:05:01.133072Z",
     "start_time": "2021-04-16T18:05:01.130850Z"
    }
   },
   "outputs": [],
   "source": [
    "# Note that the resulting Turtle is then further hand-edited and stored in the /ontologies directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0100fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
